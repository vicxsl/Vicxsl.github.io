(window.webpackJsonp=window.webpackJsonp||[]).push([[92],{638:function(s,a,t){"use strict";t.r(a);var n=t(16),e=Object(n.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"大数据工程师面试题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据工程师面试题"}},[s._v("#")]),s._v(" 大数据工程师面试题")]),s._v(" "),t("h2",{attrs:{id:"选择题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#选择题"}},[s._v("#")]),s._v(" 选择题")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("下面哪个程序负责HDFS数据存储。")]),s._v(" "),t("p",[s._v("a) NameNode \tb) Jobtracker \tc) Datanode \td) secondaryNameNode \te) tasktracker")]),s._v(" "),t("p",[s._v("答案 C datanode")])]),s._v(" "),t("li",[t("p",[s._v("HDfS 中的 block 默认保存几份？")]),s._v(" "),t("p",[s._v("a) 3 份 \tb) 2 份 \tc) 1 份 \td) 不确定")]),s._v(" "),t("p",[s._v("答案 A 默认 3 份")])]),s._v(" "),t("li",[t("p",[s._v("下列哪个程序通常与 NameNode 在一个节点启动?")]),s._v(" "),t("p",[s._v("a) SecondaryNameNode \tb) DataNode \tc) TaskTracker \td) Jobtracker")]),s._v(" "),t("p",[s._v("答案 D")])]),s._v(" "),t("li",[t("p",[s._v("HDFS 默认 Block Size")]),s._v(" "),t("p",[s._v("a) 32MB\tb) 64MB\tc) 128MB")]),s._v(" "),t("p",[s._v("答案：B")])]),s._v(" "),t("li",[t("p",[s._v("下列哪项通常是集群的最主要瓶颈")]),s._v(" "),t("p",[s._v("a) CPU \tb) 网络 \tc) 磁盘 IO \td) 内存")]),s._v(" "),t("p",[s._v("答案：C 磁盘")])])]),s._v(" "),t("blockquote",[t("p",[s._v("首先集群的目的是为了节省成本，用廉价的 pc 机，取代小型机及大型机。小型机和大型机 有什么特点？")]),s._v(" "),t("p",[s._v("1.cpu 处理能力强")]),s._v(" "),t("p",[s._v("2.内存够大，所以集群的瓶颈不可能是 a 和 d")]),s._v(" "),t("p",[s._v("3.如果是互联网有瓶颈，可以让集群搭建内网。每次写入数据都要通过网络（集群是内网）， 然后还要写入 3 份数据，所以 IO 就会打折扣。")])]),s._v(" "),t("ol",{attrs:{start:"6"}},[t("li",[t("p",[s._v("关于 SecondaryNameNode 哪项是正确的？")]),s._v(" "),t("p",[s._v("a) 它是 NameNode 的热备 \tb) 它对内存没有要求 \tc) 它的目的是帮助 NameNode 合并编辑日志，减少 NameNode 启动时间 \td) SecondaryNameNode 应与 NameNode 部署到一个节点")]),s._v(" "),t("p",[s._v("答案 C")])]),s._v(" "),t("li",[t("p",[s._v("下列哪项可以作为集群的管理？")]),s._v(" "),t("p",[s._v("a) Puppet \tb) Pdsh \tc) Cloudera Manager d) Zookeeper")]),s._v(" "),t("p",[s._v("答案 ABD \t具体可查看什么是 Zookeeper，Zookeeper 的作用是什么，在 Hadoop 及 hbase 中具体作 用是什么。")])]),s._v(" "),t("li",[t("p",[s._v("Client 端上传文件的时候下列哪项正确")]),s._v(" "),t("p",[s._v("a) 数据经过 NameNode 传递给 DataNode \tb) Client 端将文件切分为 Block，依次上传 \tc) Client 只上传数据到一台 DataNode，然后由 NameNode 负责 Block 复制工作")]),s._v(" "),t("p",[s._v("答案 B 分析：Client 向 NameNode 发起文件写入的请求。NameNode 根据文件大小和文件块配置 情况，返回给 Client 它所管理部分 DataNode 的信息。Client 将文件划分为多个 Block，根据 DataNode 的地址信息，按顺序写入到每一个 DataNode 块中。具体查看 HDFS 体系结构简介及优缺点。")])]),s._v(" "),t("li",[t("p",[s._v("下列哪个是 Hadoop 运行的模式")]),s._v(" "),t("p",[s._v("a) 单机版 \tb) 伪分布式 \tc) 分布式")]),s._v(" "),t("p",[s._v("答案 ABC 单机版,伪分布式只是学习用的。")])])]),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"面试题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试题"}},[s._v("#")]),s._v(" 面试题")]),s._v(" "),t("h3",{attrs:{id:"hadoop-的核心配置是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-的核心配置是什么"}},[s._v("#")]),s._v(" Hadoop 的核心配置是什么？")]),s._v(" "),t("p",[s._v("Hadoop 的核心配置通过两个 xml 文件来完成：1，hadoop-default.xml；2，hadoop-site.xml。 这些文件都使用 xml 格式，因此每个 xml 中都有一些属性，包括名称和值，但是当下这些文 件都已不复存在。")]),s._v(" "),t("h3",{attrs:{id:"那当下又该如何配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#那当下又该如何配置"}},[s._v("#")]),s._v(" 那当下又该如何配置？")]),s._v(" "),t("p",[s._v("Hadoop 现在拥有 3 个配置文件：1，core-site.xml；2，hdfs-site.xml；3，mapred-site.xml。这 些文件都保存在 conf/子目录下。")]),s._v(" "),t("h3",{attrs:{id:"jps-命令的用处"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#jps-命令的用处"}},[s._v("#")]),s._v(" “jps”命令的用处？")]),s._v(" "),t("p",[s._v("这个命令可以检查 Namenode、Datanode、Task Tracker、 Job Tracker 是否正常工作。")]),s._v(" "),t("h3",{attrs:{id:"❤️mapreduce-的原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️mapreduce-的原理"}},[s._v("#")]),s._v(" ❤️mapreduce 的原理?")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629867951423/image-20210825130550811.png",alt:"image-20210825130550811"}})]),s._v(" "),t("ol",[t("li",[s._v("单行文件内容作为输入")]),s._v(" "),t("li",[s._v("分布式的DataNode处理数据\n"),t("ol",[t("li",[s._v("通过Mapper处理文件，处理偏移量和数据分割")]),s._v(" "),t("li",[s._v("content 循环输出分割好的内容")])])]),s._v(" "),t("li",[s._v("拷贝数据到其他DataNode（分区好之后？）")]),s._v(" "),t("li",[s._v("Reducer处理，加工后输出数据")])]),s._v(" "),t("h3",{attrs:{id:"hdfs-存储的机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-存储的机制"}},[s._v("#")]),s._v(" HDFS 存储的机制?")]),s._v(" "),t("h3",{attrs:{id:"hdfs-写流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-写流程"}},[s._v("#")]),s._v(" HDFS 写流程")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629869083912/image-20210825132443536.png",alt:"image-20210825132443536"}})]),s._v(" "),t("p",[s._v("流程：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("client 链接 namenode 存数据")])]),s._v(" "),t("li",[t("p",[s._v("namenode 记录一条数据位置信息（元数据），告诉 client 存哪。")])]),s._v(" "),t("li",[t("p",[s._v("client 用 hdfs 的 api 将数据块（默认是 64M）存储到 datanode 上。")])]),s._v(" "),t("li",[t("p",[s._v("datanode 将数据水平备份。并且备份完将反馈 client。")])]),s._v(" "),t("li",[t("p",[s._v("client 通知 namenode 存储块完毕。")])]),s._v(" "),t("li",[t("p",[s._v("namenode 将元数据同步到内存中。")])]),s._v(" "),t("li",[t("p",[s._v("另一块循环上面的过程。")])])]),s._v(" "),t("h3",{attrs:{id:"hdfs读流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs读流程"}},[s._v("#")]),s._v(" HDFS读流程")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629869223178/image-20210825132702811.png",alt:"image-20210825132702811"}})]),s._v(" "),t("p",[s._v("流程：")]),s._v(" "),t("ol",[t("li",[s._v("client 链接 namenode，查看元数据，找到数据的存储位置。 2.")]),s._v(" "),t("li",[s._v("client 通过 hdfs 的 api 并发读取数据。")]),s._v(" "),t("li",[s._v("关闭连接。")])]),s._v(" "),t("h3",{attrs:{id:"举一个简单的例子说明-mapreduce-是怎么来运行的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#举一个简单的例子说明-mapreduce-是怎么来运行的"}},[s._v("#")]),s._v(" 举一个简单的例子说明 mapreduce 是怎么来运行的 ?")]),s._v(" "),t("p",[s._v("wordcount 的例子")]),s._v(" "),t("h3",{attrs:{id:"用-mapreduce-来实现下面需求"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#用-mapreduce-来实现下面需求"}},[s._v("#")]),s._v(" 用 mapreduce 来实现下面需求？")]),s._v(" "),t("p",[s._v("现在有 10 个文件夹,每个文件夹都有 1000000 个 url.现在让你找出 top1000000url。")]),s._v(" "),t("p",[s._v("解答：topk")]),s._v(" "),t("p",[s._v("(还可以用 treeMap, 到 1000000 了每来一个都加进去, 删掉最小的)")]),s._v(" "),t("h3",{attrs:{id:"hadoop-中-combiner-的作用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-中-combiner-的作用"}},[s._v("#")]),s._v(" hadoop 中 Combiner 的作用?")]),s._v(" "),t("p",[s._v("combiner 是 reduce 的实现，在 map 端运行计算任务，减少 map 端的输出数据。 作用就是优化。")]),s._v(" "),t("p",[s._v("但是 combiner 的使用场景是 mapreduce 的 map 和 reduce 输入输出一样。")]),s._v(" "),t("h3",{attrs:{id:"简述-hadoop-安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#简述-hadoop-安装"}},[s._v("#")]),s._v(" 简述 hadoop 安装")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629869401349/image-20210825133000964.png",alt:"image-20210825133000964"}})]),s._v(" "),t("ol",[t("li",[s._v("创建 hadoop 帐户.")]),s._v(" "),t("li",[s._v("setup.改IP.")]),s._v(" "),t("li",[s._v("安装java，并修改/etc/profile 文件，配置 java 的环境变量.")]),s._v(" "),t("li",[s._v("修改 Host 文件域名.")]),s._v(" "),t("li",[s._v("安装 SSH，配置无密钥通信.")]),s._v(" "),t("li",[s._v("解压hadoop.")]),s._v(" "),t("li",[s._v("配置 conf 文件下 hadoop-env.sh、core-site.sh、 mapre-site.sh、hdfs-site.sh.")]),s._v(" "),t("li",[s._v("配置hadoop的环境变量,")]),s._v(" "),t("li",[s._v("Hadoop namenode -format")]),s._v(" "),t("li",[s._v("Start-all")])]),s._v(" "),t("h3",{attrs:{id:"请列出-hadoop-进程名"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#请列出-hadoop-进程名"}},[s._v("#")]),s._v(" 请列出 hadoop 进程名")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629869556412/image-20210825133236037.png",alt:"image-20210825133236037"}})]),s._v(" "),t("ol",[t("li",[s._v("namenode : 管理集群，并记录 datanode 文件信息.")]),s._v(" "),t("li",[s._v("Secondname:可以做冷备，对一定范围内数据做快照性备份.")]),s._v(" "),t("li",[s._v("Datanode:存储数据")]),s._v(" "),t("li",[s._v("Jobtracker :管理任务，并将任务分配给 tasktracker.")]),s._v(" "),t("li",[s._v("Tasktracker:任务执行方.")])]),s._v(" "),t("h3",{attrs:{id:"解决下面的错误"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#解决下面的错误"}},[s._v("#")]),s._v(" 解决下面的错误")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629869649566/image-20210825133409119.png",alt:"image-20210825133409119"}})]),s._v(" "),t("p",[s._v("1、 权限问题，可能曾经用 root启动过集群。 ( 例如 hadoop搭建的集群 ,是tmp/hadoop hadoop/..... )\n2、 可能是文件夹不存在( Directory does not exist )\n3、 解决 : 删掉 tmp下的那个文件 ,或改成当前用户（ Directory /tmp/hadoop-root/ ）")]),s._v(" "),t("h3",{attrs:{id:"写出下面的命令"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#写出下面的命令"}},[s._v("#")]),s._v(" 写出下面的命令")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629869811385/image-20210825133650988.png",alt:"image-20210825133650988"}})]),s._v(" "),t("ol",[t("li",[t("p",[s._v("hadoop job -list")])]),s._v(" "),t("li",[t("p",[s._v("拿到job-id  shadoop job -kill job-id")])]),s._v(" "),t("li",[t("p",[s._v("Hadoop fs -rmr /tmp/aaa")])]),s._v(" "),t("li",[t("p",[s._v("加新节点时:\nHadoop-daemon.sh start datanode")]),s._v(" "),t("p",[s._v("Hadoop-daemon.sh start tasktracker")])]),s._v(" "),t("li",[t("p",[s._v("删除时:")]),s._v(" "),t("p",[s._v("Hadoop mradmin -refreshnodes\nHadoop dfsadmin -refreshnodes")])])]),s._v(" "),t("h3",{attrs:{id:"简述-hadoop的调度器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#简述-hadoop的调度器"}},[s._v("#")]),s._v(" 简述 hadoop的调度器")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629955077154/image-20210826131756492.png",alt:"image-20210826131756492"}})]),s._v(" "),t("p",[s._v("Fifo schedular : 默认，先进先出的原则。\nCapacity schedular : 计算能力调度器，选择占用最小、优先级高的先执行，依此类推。\nFair schedular: 公平调度，所有的 job 具有相同的资源。")]),s._v(" "),t("h3",{attrs:{id:"列出你开发-mapreduce的语言"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#列出你开发-mapreduce的语言"}},[s._v("#")]),s._v(" 列出你开发 mapreduce的语言")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629955167927/image-20210826131927559.png",alt:"image-20210826131927559"}})]),s._v(" "),t("p",[s._v("java")]),s._v(" "),t("h3",{attrs:{id:"书写程序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#书写程序"}},[s._v("#")]),s._v(" 书写程序")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629955235358/image-20210826132034992.png",alt:"image-20210826132034992"}})]),s._v(" "),t("p",[s._v("wordcount")]),s._v(" "),t("h3",{attrs:{id:"不同语言的优缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#不同语言的优缺点"}},[s._v("#")]),s._v(" 不同语言的优缺点")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629955257822/image-20210826132057466.png",alt:"image-20210826132057466"}})]),s._v(" "),t("p",[s._v("hadoop")]),s._v(" "),t("p",[s._v("hadoop是 java写的， java的集成效果最好，并且平台环境统一。")]),s._v(" "),t("h3",{attrs:{id:"hive有哪些保存元数据的方式-个有什么特点。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive有哪些保存元数据的方式-个有什么特点。"}},[s._v("#")]),s._v(" hive有哪些保存元数据的方式，个有什么特点。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629955288440/image-20210826132128077.png",alt:"image-20210826132128077"}})]),s._v(" "),t("p",[s._v("1、 内存数据库 derby，安装小，但是数据存在内存，不稳定\n2、 mysql数据库，数据存储模式可以自己设置，持久化好，查看方便。")]),s._v(" "),t("p",[s._v("combiner和 partition的作用")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1629955318528/image-20210826132158158.png",alt:"image-20210826132158158"}})]),s._v(" "),t("p",[s._v("combiner是 reduce的实现，在 map端运行计算任务，减少 map端的输出数据。\n"),t("strong",[s._v("作用就是优化。")]),s._v("\n但是combiner的使用场景是mapreduce的 map输出结果和 reduce输入输出一样。")]),s._v(" "),t("p",[t("strong",[s._v("partition的默认实现是 hashpartition，是 map端将数据按照 reduce个数取余")]),s._v("，进行分区，\n不同的 reduce来 copy自己的数据。\npartition的作用是将数据分到不同的 reduce进行计算，加快计算效果。")]),s._v(" "),t("h3",{attrs:{id:"hive内部表和外部表的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive内部表和外部表的区别"}},[s._v("#")]),s._v(" hive内部表和外部表的区别")]),s._v(" "),t("p",[s._v("内部表：加载数据到 hive所在的 hdfs目录， 删除时，元数据和数据文件都删除。\n外部表：不加载数据到 hive所在的 hdfs目录，删除时，只删除表结构。")]),s._v(" "),t("h3",{attrs:{id:"hbase的-rowkey怎么创建好-列族怎么创建比较好"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hbase的-rowkey怎么创建好-列族怎么创建比较好"}},[s._v("#")]),s._v(" hbase的 rowkey怎么创建好？列族怎么创建比较好？")]),s._v(" "),t("p",[s._v("hbase存储时，数据按照 Row key的字典序 (byte order)排序存储。设计 key时，要充分排序\n存储这个特性，将经常一起读取的行存储放到一起。 (位置相关性 )")]),s._v(" "),t("p",[s._v("一个列族在数据底层是一个文件，所以将经常一起查询的列放到一个列族中，列族尽量少，减少文件的寻址时间。减少文件的寻址时间。")]),s._v(" "),t("h3",{attrs:{id:"❤️用-mapreduce怎么处理数据倾斜问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️用-mapreduce怎么处理数据倾斜问题"}},[s._v("#")]),s._v(" ❤️用 mapreduce怎么处理数据倾斜问题？")]),s._v(" "),t("p",[s._v("数据倾斜：")]),s._v(" "),t("p",[s._v("map /reduce程序执行时， reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长，这是因为某一个 key的条数比其他key多很多（有时是百倍或者千倍之多），这条 key所在的 reduce节点所处理的数据量比其他节点就大很多，从而导致某几个节点迟迟运行不完，此称之为数据倾斜。\n用hadoop程序进行数据关联时，常碰到数据倾斜的情况，这里提供一种解决方法。")]),s._v(" "),t("p",[s._v("自己实现"),t("strong",[s._v("partition类，用")]),s._v(" "),t("strong",[s._v("key和 value相加取 hash值")]),s._v("：")]),s._v(" "),t("p",[s._v("方式1：\n源代码：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" numReduceTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MAX_VALUE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" numReduceTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n修改后\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" numReduceTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("（key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MAX_VALUE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" numReduceTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("p",[s._v("方式2：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HashPartitioner")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Partitioner")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" aa"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** Use {@link Object#hashCode()} to partition. */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" numReduceTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("aa"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MAX_VALUE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" numReduceTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("blockquote",[t("p",[s._v("重新分区器")])]),s._v(" "),t("h3",{attrs:{id:"hadoop框架中怎么来优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop框架中怎么来优化"}},[s._v("#")]),s._v(" hadoop框架中怎么来优化")]),s._v(" "),t("ol",[t("li",[s._v("从应用程序角度进行优化。由于 mapreduce是迭代逐行解析数据文件的，怎样在迭代的情况下，编写高效率的应用程序，是一种优化思路。")]),s._v(" "),t("li",[s._v("对 Hadoop参数进行调优。当前 hadoop系统有 190多个配置参数，怎样调整这些参数，使 hadoop作业运行尽可能的快，也是一种优化思路。")]),s._v(" "),t("li",[s._v("从系统实现角度进行优化。这种优化难度是最大的，它是从 hadoop实现机制角度，发现当前 Hadoop设计和实现上的缺点，然后进行源码级地修改。该方法虽难度大，但往往效果明显。")]),s._v(" "),t("li",[s._v("linux内核参数调整")])]),s._v(" "),t("h3",{attrs:{id:"从应用程序角度进行优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#从应用程序角度进行优化"}},[s._v("#")]),s._v(" 从应用程序角度进行优化")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("避免不必要的 reduce任务")]),s._v(" "),t("p",[s._v("如果mapreduce程序中 reduce是不必要的，那么我们可以在 map中处理数据 , Reducer设置\n为 0。这样 避免了多余的 reduce任务。")])]),s._v(" "),t("li",[t("p",[s._v("为 job添加一个 Combiner")]),s._v(" "),t("p",[s._v("为job添加一个 combiner可以大大减少 shuffle阶段从 map task拷贝给远程 reduce task的数据量。一般而言， combiner与 reducer相同。")])]),s._v(" "),t("li",[t("p",[s._v("根据处理数据特征使用最适合和简洁的 Writable类型\nText对象使用起来很方便，但它在由数值转换到文本或是由 UTF8字符串转换到文本时都是低效的，且会消耗大量的 CPU时间。当处理那些非文本的数据时，可以使用二进制的 Writable类型，如 IntWritable FloatWritable等。二进制 writable好处：避免文件转换的消耗；使map task中间结果占用更少的空间。")])]),s._v(" "),t("li",[t("p",[s._v("重用 Writable类型\n很多MapReduce用户常犯的一个错误是，在一个 map/reduce方法中为每个输出都创建Writable对象。例如，你的 Wordcout mapper方法可能这样写：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("map")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n…\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\toutput"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("collect")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IntWritable")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("这样会导致程序分配出成千上万个短周期的对象。Java垃圾收集器就要为此做很多的工作。垃圾收集器就要为此做很多的工作。更有效的写法是：更有效的写法是：")]),s._v(" "),t("p",[s._v("抽取对象")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyMapper")]),s._v(" … "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),s._v(" wordText "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    \n"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IntWritable")]),s._v(" one "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IntWritable")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("map")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" word"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            wordText"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            output"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("collect")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("wordText"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" one"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("使用使用StringBuffer而不是而不是String")])])]),s._v(" "),t("p",[s._v("当需要对字符串进行操作时，"),t("strong",[s._v("使用StringBuffer而不是而不是String，String是是read--only的，如果对的，如果对它进行修改，会产生临时对象")]),s._v("，而StringBuffer是可修改的，不会产生临时对象。是可修改的，不会产生临时对象。")]),s._v(" "),t("h3",{attrs:{id:"对参数进行调优"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#对参数进行调优"}},[s._v("#")]),s._v(" 对参数进行调优")]),s._v(" "),t("p",[s._v("查看linux的服务，可以关闭不必要的服务")]),s._v(" "),t("p",[s._v("ntsysv")]),s._v(" "),t("p",[t("strong",[s._v("停止打印服务")])]),s._v(" "),t("p",[s._v("/etc/init.d/cups stop")]),s._v(" "),t("p",[s._v("chkconfig cups off")]),s._v(" "),t("p",[t("strong",[s._v("关闭ipv6")])]),s._v(" "),t("p",[s._v("vim /etc/modprobe.conf")]),s._v(" "),t("p",[s._v("添加内容")]),s._v(" "),t("p",[s._v("alias net-pf-10 off alias ipv6 off")]),s._v(" "),t("p",[t("strong",[s._v("调整文件最大打开数")])]),s._v(" "),t("p",[s._v("查看： ulimit -a  结果：open files (-n) 1024")]),s._v(" "),t("p",[s._v("临时修改： ulimit -n 4096")]),s._v(" "),t("p",[s._v("持久修改：")]),s._v(" "),t("p",[s._v("vi /etc/security/limits.conf在文件最后加上：")]),s._v(" "),t("ul",[t("li",[s._v("soft nofile 65535")]),s._v(" "),t("li",[s._v("hard nofile 65535")]),s._v(" "),t("li",[s._v("soft nproc 65535")]),s._v(" "),t("li",[s._v("hard nproc 65535")])]),s._v(" "),t("p",[t("strong",[s._v("修改linux内核参数")])]),s._v(" "),t("p",[s._v("vi /etc/sysctl.conf")]),s._v(" "),t("p",[s._v("添加")]),s._v(" "),t("p",[s._v("net.core.somaxconn = 32768")]),s._v(" "),t("p",[s._v("web应用中listen函数的backlog默认会给我们内核参数的net.core.somaxconn限制到128，而nginx定义的NGX_LISTEN_BACKLOG默认为511，所以有必要调整这个值。")]),s._v(" "),t("p",[s._v("调整swap分区什么时候使用：")]),s._v(" "),t("p",[s._v("查看：cat /proc/sys/vm/swappiness")]),s._v(" "),t("p",[s._v("设置：vi /etc/sysctl.conf")]),s._v(" "),t("p",[s._v("​\t在这个文档的最后加上这样一行: vm.swappiness=10")]),s._v(" "),t("p",[s._v("​\t表示物理内存使用到90%（100-10=90）的时候才使用swap交换区")]),s._v(" "),t("p",[t("strong",[s._v("关闭noatime")])]),s._v(" "),t("p",[s._v("vi /etc/fstab /dev/sda2/data ext3\t noatime,nodiratime 0 0")]),s._v(" "),t("p",[t("strong",[s._v("设置readahead buffer")])]),s._v(" "),t("p",[s._v("blockdev --setra READAHEAD 512 /dev/sda")]),s._v(" "),t("p",[t("strong",[s._v("以下是修改mapred-site.xml文件")])]),s._v(" "),t("p",[t("strong",[s._v("修改最大槽位数")])]),s._v(" "),t("p",[s._v("槽位数是在各个tasktracker上的mapred-site.xml上设置的，默认都是2")]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("<property>")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("<name>mapred.tasktracker.map.tasks.maximum</name>")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#++++maptask的最大数")]),s._v("\n<value>2</value>\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("</property>")]),s._v(" \n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("<property>")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("<name>mapred.tasktracker.reduce.tasks.maximum</name>")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#++++reducetask的最大数 ")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("<value>2</value>")]),s._v(" \n</property>\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("p",[t("strong",[s._v("调整心跳间隔")])]),s._v(" "),t("p",[s._v("集群规模小于300时，心跳间隔为300毫秒")]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapreduce.jobtracker.heartbeat.interval.min")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("心跳时间 ")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.heartbeats.in.second")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("集群每增加多少节点，时间增加下面的值 ")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapreduce.jobtracker.heartbeat.scaling.factor")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("集群每增加上面的个数，心跳增多少")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[t("strong",[s._v("启动带外心跳")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapreduce.tasktracker.outofband.heartbeat")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认是false")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("配置多块磁盘")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapreduce.local.dir")]),s._v(" \n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("配置RPC hander数目")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.job.tracker.handler.count")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认是10，可以改成50，根据机器的能力")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("配置HTTP线程数目")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("tasktracker.http.threads")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认是40，可以改成100 根据机器的能力")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("选择合适的压缩方式")])]),s._v(" "),t("div",{staticClass:"language-xml line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[s._v("以snappy为例： \n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("mapred.compress.map.output"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("</")]),s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("true"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("</")]),s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("</")]),s._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" \n\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("mapred.map.output.compression.codec"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("</")]),s._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("org.apache.hadoop.io.compress.SnappyCodec"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("</")]),s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("</")]),s._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("p",[t("strong",[s._v("启用推测执行机制")])]),s._v(" "),t("blockquote",[t("p",[s._v("​\t\t推测执行(Speculative Execution)是指在分布式集群环境下，因为程序BUG，负载不均衡或者资源分布不均等原因，造成同一个job的多个task运行速度不一致，有的task运行速度明显慢于其他task（比如：一个job的某个task进度只有10%，而其他所有task已经运行完毕），则这些task拖慢了作业的整体执行进度，为了避免这种情况发生，Hadoop会为该task启动备份任务，让该speculative task与原始task同时处理一份数据，哪个先运行完，则将谁的结果作为最终结果。")]),s._v(" "),t("p",[s._v("​\t\t推测执行优化机制采用了典型的以空间换时间的优化策略，它同时启动多个相同task（备份任务）处理相同的数据块，哪个完成的早，则采用哪个task的结果，这样可防止拖后腿Task任务出现，进而提高作业计算速度，但是，这样却会占用更多的资源，在集群资源紧缺的情况下，设计合理的推测执行机制可在多用少量资源情况下，减少大作业的计算时间。")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.map.tasks.speculative.execution")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认是true")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.rduce.tasks.speculative.execution")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认是true")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[t("strong",[s._v("设置失败容忍度")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.max.map.failures.percent")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("作业允许失败的map最大比例 默认值0，即0%")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.max.reduce.failures.percent")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("作业允许失败的reduce最大比例 默认值0，即0%")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.map.max.attemps")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("失败后最多重新尝试的次数 默认是4 ")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.reduce.max.attemps")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("失败后最多重新尝试的次数 默认是4")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("p",[t("strong",[s._v("启动jvm重用功能")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.job.reuse.jvm.num.tasks")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认值1，表示只能启动一个task，若为-1，表示可以最多运行数不限制")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("设置任务超时时间")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.task.timeout")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认值600000毫秒，也就是10分钟。")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("合理的控制reduce的启动时间")])]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.reduce.slowstart.completed.maps")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认值0.05 表示map任务完成5%时，开始启动reduce任务")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("跳过坏记录")])]),s._v(" "),t("p",[s._v("当任务失败次数达到该值时，才会进入skip mode，即启用跳过坏记录数功能,也就是先试几次，不行就跳过")]),s._v(" "),t("p",[s._v("mapred.skip.attempts.to.start.skipping 默认值 2")]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("map最多允许跳过的记录数")]),s._v(" \n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.skip.map.max.skip.records")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认值0，为不启用 ")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("reduce最多允许跳过的记录数")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.skip.reduce.max.skip.records")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认值0，为不启用")]),s._v("\n\n换记录存放的目录\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("mapred.skip.out.dir")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("默认值${mapred.output.dir}/_logs/")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("h3",{attrs:{id:"我们开发-job-时-是否可以去掉-reduce-阶段"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#我们开发-job-时-是否可以去掉-reduce-阶段"}},[s._v("#")]),s._v(" 我们开发 job 时，是否可以去掉 reduce 阶段")]),s._v(" "),t("p",[s._v("可以。设置 reduce 数为 0 即可。")]),s._v(" "),t("h3",{attrs:{id:"datanode-在什么情况下不会备份"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#datanode-在什么情况下不会备份"}},[s._v("#")]),s._v(" datanode 在什么情况下不会备份")]),s._v(" "),t("p",[s._v("datanode 在强制关闭或者非正常断电不会备份。")]),s._v(" "),t("h3",{attrs:{id:"combiner-出现在那个过程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#combiner-出现在那个过程"}},[s._v("#")]),s._v(" combiner 出现在那个过程")]),s._v(" "),t("p",[s._v("出现在 map 阶段的 map 方法后。")]),s._v(" "),t("h3",{attrs:{id:"😺hdfs-的体系结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#😺hdfs-的体系结构"}},[s._v("#")]),s._v(" 😺hdfs 的体系结构")]),s._v(" "),t("p",[s._v("hdfs 有 namenode、secondraynamenode、datanode 组成。")]),s._v(" "),t("p",[s._v("为 n+1 模式")]),s._v(" "),t("p",[s._v("namenode 负责管理 datanode 和记录元数据")]),s._v(" "),t("p",[s._v("secondraynamenode 负责合并日志")]),s._v(" "),t("p",[s._v("datanode 负责存储数据")]),s._v(" "),t("h3",{attrs:{id:"_3-个-datanode-中有一个-datanode-出现错误会怎样"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-个-datanode-中有一个-datanode-出现错误会怎样"}},[s._v("#")]),s._v(" 3 个 datanode 中有一个 datanode 出现错误会怎样？")]),s._v(" "),t("p",[s._v("这个 datanode 的数据会在其他的 datanode 上重新做备份。")]),s._v(" "),t("h3",{attrs:{id:"描述一下-hadoop-中-有哪些地方使用了缓存机制-作用分别是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#描述一下-hadoop-中-有哪些地方使用了缓存机制-作用分别是什么"}},[s._v("#")]),s._v(" 描述一下 hadoop 中，有哪些地方使用了缓存机制， 作用分别是什么？")]),s._v(" "),t("p",[s._v("在 mapreduce 提交 job 的获取 id 之后，会将所有文件存储到分布式缓存上，这样文件可以 被所有的 mapreduce 共享。")]),s._v(" "),t("h3",{attrs:{id:"如何确定-hadoop-集群的健康状态"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何确定-hadoop-集群的健康状态"}},[s._v("#")]),s._v(" 如何确定 hadoop 集群的健康状态")]),s._v(" "),t("p",[s._v("通过页面监控,脚本监控。")]),s._v(" "),t("h3",{attrs:{id:"生产环境中为什么建议使用外部表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#生产环境中为什么建议使用外部表"}},[s._v("#")]),s._v(" 生产环境中为什么建议使用外部表？")]),s._v(" "),t("p",[s._v("1、因为外部表不会加载数据到 hive，减少数据传输、数据还能共享。")]),s._v(" "),t("p",[s._v("2、hive 不会修改数据，所以无需担心数据的损坏")]),s._v(" "),t("p",[s._v("3、 删除表时，只删除表结构、不删除数据。")]),s._v(" "),t("h2",{attrs:{id:"面试真题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试真题"}},[s._v("#")]),s._v(" 面试真题")]),s._v(" "),t("h3",{attrs:{id:"请选择你熟练掌握的hadoop版本-并基于此回答下列问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#请选择你熟练掌握的hadoop版本-并基于此回答下列问题"}},[s._v("#")]),s._v(" 请选择你熟练掌握的hadoop版本，并基于此回答下列问题")]),s._v(" "),t("p",[s._v("hadoop1.0")]),s._v(" "),t("h4",{attrs:{id:"hadoop的核心配置文件名称是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop的核心配置文件名称是什么"}},[s._v("#")]),s._v(" hadoop的核心配置文件名称是什么？")]),s._v(" "),t("p",[s._v("core-site.xml")]),s._v(" "),t("h4",{attrs:{id:"jps-命令的用处-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#jps-命令的用处-2"}},[s._v("#")]),s._v(' "jps"命令的用处？')]),s._v(" "),t("p",[s._v("查看hadoop节点进程")]),s._v(" "),t("h4",{attrs:{id:"如何检查namenode是否正常运行-重启namenode的命令是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何检查namenode是否正常运行-重启namenode的命令是什么"}},[s._v("#")]),s._v(" 如何检查namenode是否正常运行？重启namenode的命令是什么？")]),s._v(" "),t("p",[s._v("通过节点信息和浏览器查看，通过脚本监控\nhadoop deamon.sh start namenode\nhdfs deamon.sh start namenode")]),s._v(" "),t("h4",{attrs:{id:"避免namenode故障导致集群宕机的解决方法是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#避免namenode故障导致集群宕机的解决方法是什么"}},[s._v("#")]),s._v(" 避免namenode故障导致集群宕机的解决方法是什么？")]),s._v(" "),t("p",[s._v("自己书写脚本监控重启")]),s._v(" "),t("h4",{attrs:{id:"hbase数据库对行键的设计要求是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hbase数据库对行键的设计要求是什么"}},[s._v("#")]),s._v(" hbase数据库对行键的设计要求是什么？")]),s._v(" "),t("p",[s._v("行健以字典序排列，设计时充分利用这个特点，将经常一起查询的行健设计在一起，例\n如时间戳结尾，用户名开头（位置相关性）")]),s._v(" "),t("h3",{attrs:{id:"hadoop面试业务题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop面试业务题"}},[s._v("#")]),s._v(" Hadoop面试业务题")]),s._v(" "),t("p",[t("strong",[s._v("业务场景：")])]),s._v(" "),t("h4",{attrs:{id:"用户访问网站时-每个页面会上报一条pv数据-同时做一些业务操作-会上报事件数据-如"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#用户访问网站时-每个页面会上报一条pv数据-同时做一些业务操作-会上报事件数据-如"}},[s._v("#")]),s._v(" 用户访问网站时，每个页面会上报一条pv数据，同时做一些业务操作，会上报事件数据，如：")]),s._v(" "),t("ol",[t("li",[s._v("用户浏览页面（PV）")]),s._v(" "),t("li",[s._v("用户事件行为（开户，下单买基金......）")]),s._v(" "),t("li",[s._v("页面click点击（包含各种超链接，可点击按钮，radio，checkbox......）")])]),s._v(" "),t("p",[s._v("每日，以上3项的上报数大致10000000")]),s._v(" "),t("p",[t("strong",[s._v("业务需求：")])]),s._v(" "),t("ol",[t("li",[s._v("需要按时间维度（天，周），某种业务维度（开户，买基金...），定时做统计（总人数，金额等）。")])]),s._v(" "),t("p",[s._v("例：过去一周（隔日）的pv，uv数，交易总金额。")]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("需要回溯历史数据，如：过去某个时间点（段），访问过某页面的用户，在某个时间点（段）导致某种业务发生的统计数据。")])]),s._v(" "),t("p",[s._v("例：在2015-01-01至2015-01-31访问A页面，并在2015-01-01至2015-03-31开户，下单的用户数")]),s._v(" "),t("p",[t("strong",[s._v("技术方案：")])]),s._v(" "),t("p",[s._v("请给出你的设计方案，比如使用哪些技术框架，该框架起到的作用等。")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("用hive分析业务数据即可")])]),s._v(" "),t("li",[t("p",[s._v("讲数据导入到hive中")]),s._v(" "),t("p",[s._v("sql的设计思路：多表关联")]),s._v(" "),t("ol",[t("li",[s._v("找到所有在 2015 01 01到 2015 01 31时间内访问 A页面的用户")]),s._v(" "),t("li",[s._v("在这些用户中筛选在 2015 01 01到 2015 03 31下单的用户")]),s._v(" "),t("li",[s._v("统计总数")])])])]),s._v(" "),t("h3",{attrs:{id:"你们数据库怎么导入-hive-的-有没有出现问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#你们数据库怎么导入-hive-的-有没有出现问题"}},[s._v("#")]),s._v(" 你们数据库怎么导入 hive 的 ,有没有出现问题")]),s._v(" "),t("p",[s._v("在导入hive的时候，如果数据库中有 blob或者 text字段，会报错，解决方案在 sqoop笔记中。")]),s._v(" "),t("h3",{attrs:{id:"公司技术选型可能利用-storm-进行实时计算-讲解一下storm"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#公司技术选型可能利用-storm-进行实时计算-讲解一下storm"}},[s._v("#")]),s._v(" 公司技术选型可能利用 storm 进行实时计算 ,讲解一下storm")]),s._v(" "),t("p",[s._v("描述下storm的设计模式，是基于 work、 excutor、 task的方式运行代码，由 spout、 bolt组\n成等等")]),s._v(" "),t("h3",{attrs:{id:"一个-datanode-宕机-怎么一个流程恢复"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一个-datanode-宕机-怎么一个流程恢复"}},[s._v("#")]),s._v(" 一个 datanode 宕机 ,怎么一个流程恢复")]),s._v(" "),t("p",[s._v("将datanode数据删除，重新当成新节点加入即可。")]),s._v(" "),t("h3",{attrs:{id:"hbase-的特性-以及你怎么去设计-rowkey-和-columnfamily-怎么去建一个-table"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hbase-的特性-以及你怎么去设计-rowkey-和-columnfamily-怎么去建一个-table"}},[s._v("#")]),s._v(" Hbase 的特性 ,以及你怎么去设计 rowkey 和 columnFamily ,怎么去建一个 table")]),s._v(" "),t("p",[s._v("hbase是列式数据库， rowkey是字典序的，设计时的规则同上。\n每个列族是一个文件，将经常一起查询的列放到同一个列族中，减少文件的寻址时间。")]),s._v(" "),t("h3",{attrs:{id:"❤️redis-传统数据库-hbase-hive-每个之间的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️redis-传统数据库-hbase-hive-每个之间的区别"}},[s._v("#")]),s._v(" ❤️Redis,传统数据库 ,hbase,hive 每个之间的区别")]),s._v(" "),t("ul",[t("li",[s._v("redis：分布式缓存，强调缓存，内存中数据")]),s._v(" "),t("li",[s._v("传统数据库：注重关系")]),s._v(" "),t("li",[s._v("hbase：列式数据库，无法做关系数据库的主外键，用于存储海量数据，底层基于 hdfs")]),s._v(" "),t("li",[s._v("hive：数据仓库工具，底层是 mapreduce。不是数据库，不能用来做用户的交互存储")])]),s._v(" "),t("h3",{attrs:{id:"❤️shuffle-阶段-你怎么理解的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️shuffle-阶段-你怎么理解的"}},[s._v("#")]),s._v(" ❤️shuffle 阶段 ,你怎么理解的")]),s._v(" "),t("p",[s._v("shuffle的过程说清楚，目的说清楚")]),s._v(" "),t("h3",{attrs:{id:"mapreduce-的-map-数量-和-reduce-数量-怎么确定-怎么配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-的-map-数量-和-reduce-数量-怎么确定-怎么配置"}},[s._v("#")]),s._v(" Mapreduce 的 map 数量 和 reduce 数量 怎么确定 ,怎么配置")]),s._v(" "),t("p",[s._v("map的数量有数据块决定， reduce数量随便配置。")]),s._v(" "),t("h3",{attrs:{id:"storm实时计算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#storm实时计算"}},[s._v("#")]),s._v(" storm实时计算")]),s._v(" "),t("p",[s._v("唯一难住我的是他说实时计算 ,storm 如果碰上了复杂逻辑 ,需要算很长的时间 ,你怎么去优化 ,怎么保证实时性")]),s._v(" "),t("h3",{attrs:{id:"hive-你们用的是外部表还是内部表-有没有写过udf-hive-的版本"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive-你们用的是外部表还是内部表-有没有写过udf-hive-的版本"}},[s._v("#")]),s._v(" Hive 你们用的是外部表还是内部表 ,有没有写过UDF,hive 的版本")]),s._v(" "),t("p",[s._v("外部表和内部表的区别")]),s._v(" "),t("h3",{attrs:{id:"hadoop-的版本"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-的版本"}},[s._v("#")]),s._v(" Hadoop 的版本")]),s._v(" "),t("p",[s._v("1.04、 1.20都为稳定版，是两个常用的 hadoop1版本。")]),s._v(" "),t("h3",{attrs:{id:"实时流式计算的结果内容有哪些-你们需要统计出来么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实时流式计算的结果内容有哪些-你们需要统计出来么"}},[s._v("#")]),s._v(" 实时流式计算的结果内容有哪些 ,你们需要统计出来么")]),s._v(" "),t("h3",{attrs:{id:"设计日志收集分析系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设计日志收集分析系统"}},[s._v("#")]),s._v(" 设计日志收集分析系统")]),s._v(" "),t("p",[s._v("日志分布在各个业务系统中。我们需要对当天的日志进行实时汇总统计，同时又能查询历史的汇总数据（可以围绕PV、UV、IP等指标进行阐述）")]),s._v(" "),t("ol",[t("li",[s._v("通过 flume将不同系统的日志收集到 kafka中")]),s._v(" "),t("li",[s._v("通过 storm实时的处理 PV、 UV、 IP")]),s._v(" "),t("li",[s._v("通过 kafka的 consumer将日志生产到 hbase中。")]),s._v(" "),t("li",[s._v("通过离线的 mapreduce或者 hive，处理 hbase中的数据")])]),s._v(" "),t("h3",{attrs:{id:"如果你来做技术分享-你会选择什么主题-课程安排时怎么样的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如果你来做技术分享-你会选择什么主题-课程安排时怎么样的"}},[s._v("#")]),s._v(" 如果你来做技术分享，你会选择什么主题，课程安排时怎么样的？")]),s._v(" "),t("p",[s._v("大体分为3个部分 :\n1、 离线 hadoop技术分享（ mapreduce、 hive）\n2、 nosql数据库hbase分享\n3、 实时流计算分享")]),s._v(" "),t("h3",{attrs:{id:"hive语句实现wordcount"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive语句实现wordcount"}},[s._v("#")]),s._v(" Hive语句实现WordCount")]),s._v(" "),t("p",[s._v("假设数据存储在hadoop下，路径为：/home/hadoop/wordcount里面全是一些单词")]),s._v(" "),t("ol",[t("li",[s._v("建表")]),s._v(" "),t("li",[s._v("分组（group by）统计wordcount")])]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" table1 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("group")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h3",{attrs:{id:"大数据相同字符比对"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据相同字符比对"}},[s._v("#")]),s._v(" 大数据相同字符比对")]),s._v(" "),t("p",[s._v("给定a，b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，找出a、b文件共同的url？")]),s._v(" "),t("p",[s._v("可以估计每个文件的大小为50G*64=298G，远远大于内存限制的4G.所以不可能将其完全加载到内存中处理。考虑采取"),t("strong",[s._v("分而治之")]),s._v("的方法。")]),s._v(" "),t("ol",[t("li",[s._v("将文件存储到 hdfs中，这样每个文件为 64M或者是 128M")]),s._v(" "),t("li",[s._v("分别对两个文件的 url进行去重、排序输出，这样能排除a文件中相同的url，b文件也一样")]),s._v(" "),t("li",[s._v("对 a、b两个文件处理后的结果进行 wordcount，并且在 reduce中判断单词个数，个数为 2的时候输出，这样就找到了 a、 b文件中的相同 url。")]),s._v(" "),t("li",[s._v("此计算步骤中的每一步加载到内存中的文件大小都不会超过 64M，远远小于 4G。")])]),s._v(" "),t("h3",{attrs:{id:"😶一亿个数据获取前100个最大值-步骤及算法复杂度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#😶一亿个数据获取前100个最大值-步骤及算法复杂度"}},[s._v("#")]),s._v(" 😶一亿个数据获取前100个最大值（步骤及算法复杂度）")]),s._v(" "),t("p",[s._v("topk，强调使用treemap是为了节省计算空间")]),s._v(" "),t("h3",{attrs:{id:"实时数据统计会用到哪些技术-他们各自的应用场景及区别是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实时数据统计会用到哪些技术-他们各自的应用场景及区别是什么"}},[s._v("#")]),s._v(" 实时数据统计会用到哪些技术，他们各自的应用场景及区别是什么？")]),s._v(" "),t("p",[s._v("flume：日志收集系统，主要用于系统日志的收集\nkafka：消息队列，进行消息的缓存和系统的解耦\nstorm：实时计算框架，进行流式的计算")]),s._v(" "),t("h3",{attrs:{id:"string和stringbuffer的区别-stringbuffer和stringbuilder的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#string和stringbuffer的区别-stringbuffer和stringbuilder的区别"}},[s._v("#")]),s._v(" String和StringBuffer的区别，StringBuffer和StringBuilder的区别")]),s._v(" "),t("p",[s._v("简单地说，就是一个变量和常量的关系。StringBuffer对象的内容可以修改；而 String对象一旦产生后就不可以被修改，重新赋值其实是两个对象。")]),s._v(" "),t("p",[s._v("StringBuilder：线程非安全的\nStringBuffer：线程安全的")]),s._v(" "),t("p",[s._v("当我们在字符串缓冲区被多个线程使用时， JVM不能保证 StringBuilder的操作是安全的，虽然他的速度最快。但是可以保证 StringBuffer是可以正确操作的。")]),s._v(" "),t("p",[s._v("当然大多数情况下就是我们是在单线程下进行的操作，所以大多数情况下是建议用 StringBuilder而不用StringBuffer的，就是速度的原因。")]),s._v(" "),t("h2",{attrs:{id:""}},[t("a",{staticClass:"header-anchor",attrs:{href:"#"}},[s._v("#")])]),s._v(" "),t("h3",{attrs:{id:"❤️hashtable和hashmap、arraylist和vector、arraylist和linkedlist的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️hashtable和hashmap、arraylist和vector、arraylist和linkedlist的区别"}},[s._v("#")]),s._v(" ❤️HashTable和HashMap、ArrayList和Vector、ArrayList和LinkedList的区别")]),s._v(" "),t("h4",{attrs:{id:"hashmap不是线程安全的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap不是线程安全的"}},[s._v("#")]),s._v(" HashMap不是线程安全的")]),s._v(" "),t("p",[s._v("hastmap是一个接口是map接口的子接口，是将键映射到值的对象，其中键和值都是对象，并且不能包含重复键，但可以包含重复值。HashMap允许null key和null value，而hashtable不允许。")]),s._v(" "),t("p",[s._v("HashTable是线程安全的一个Collection")]),s._v(" "),t("p",[s._v("HashMap是Hashtable的轻量级实现（非线程安全的实现），他们都完成了Map接口，主要区别在于HashMap允许空（null）键值（key）,由于非线程安全，效率上可能高于Hashtable。 HashMap允许将null作为一个entry的key或者value，而Hashtable不允许。")]),s._v(" "),t("p",[s._v("HashMap把Hashtable的contains方法去掉了，改成containsvalue和containsKey。因为contains方法容易让人引起误解。")]),s._v(" "),t("p",[s._v("Hashtable继承自Dictionary类，而HashMap是Java1.2引进的Map interface的一个实现。 最大的不同是，Hashtable的方法是Synchronize的，而HashMap不是，在多个线程访问Hashtable时，不需要自己为它的方法实现同步，而HashMap 就必须为之提供外同步。 Hashtable和HashMap采用的hash/rehash算法都大概一样，所以性能不会有很大的差。")]),s._v(" "),t("h4",{attrs:{id:"hashtable对比hashmap"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashtable对比hashmap"}},[s._v("#")]),s._v(" HashTable对比HashMap")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("hashmap")]),s._v(" "),t("th",[s._v("线程不安全")]),s._v(" "),t("th",[s._v("允许有null的键和值")]),s._v(" "),t("th",[s._v("效率高一点")]),s._v(" "),t("th",[s._v("方法不是Synchronize的要提供外同步")]),s._v(" "),t("th",[s._v("有containsvalue和containsKey方法")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("hashtable")]),s._v(" "),t("td",[s._v("线程安全")]),s._v(" "),t("td",[s._v("不允许有null的键和值")]),s._v(" "),t("td",[s._v("效率稍低")]),s._v(" "),t("td",[s._v("方法是是Synchronize的")]),s._v(" "),t("td",[s._v("有contains方法")])])])]),s._v(" "),t("h4",{attrs:{id:"hashtable和hashmap类有三个重要的不同之处。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashtable和hashmap类有三个重要的不同之处。"}},[s._v("#")]),s._v(" Hashtable和HashMap类有三个重要的不同之处。")]),s._v(" "),t("p",[s._v("第一个不同主要是历史原因。Hashtable是基于陈旧的Dictionary类的，HashMap是Java 1.2引进的Map接口的一个实现。")]),s._v(" "),t("p",[s._v("也许最重要的不同是Hashtable的方法是同步的，而HashMap的方法不是。这就意味着，虽然你可以不用采取任何特殊的行为就可以在一个多线程的应用程序中用一个Hashtable，但你必须同样地为一个HashMap提供外同步。一个方便的方法就是利用Collections类的静态的synchronizedMap()方法，它创建一个线程安全的Map对象，并把它作为一个封装的对象来返回。这个对象的方法可以让你同步访问潜在的HashMap。这么做的结果就是当你不需要同步时，你不能切断Hashtable中的同步（比如在一个单线程的应用程序中），而且同步增加了很多处理费用。")]),s._v(" "),t("p",[s._v("第三点不同是，只有HashMap可以让你将空值作为一个表的条目的key或value。HashMap中只有一条记录可以是一个空的key，但任意数量的条目可以是空的value。这就是说，如果在表中没有发现搜索键，或者如果发现了搜索键，但它是一个空的值，那么get()将返回null。如果有必要，用containKey()方法来区别这两种情况。")]),s._v(" "),t("p",[s._v("一些资料建议，当需要同步时，用Hashtable，反之用HashMap。但是，因为在需要时，HashMap可以被同步，HashMap的功能比Hashtable的功能更多，而且它不是基于一个陈旧的类的，所以有人认为，在各种情况下，HashMap都优先于Hashtable。")]),s._v(" "),t("h4",{attrs:{id:"vector-arraylist"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#vector-arraylist"}},[s._v("#")]),s._v(" Vector & ArrayList")]),s._v(" "),t("p",[s._v("Vector的方法都是同步的 (Synchronized),是线程安全的 (thread safe)，而 ArrayList的方法不是，由于线程的同步必然要影响性能，因此 ,ArrayList的性能比Vector好。\n2 当 Vector或 ArrayList中的元素超过它的初始大小时 ,Vector会将它的容量翻倍 ,而 ArrayList只增加50%的大小，这样 ,ArrayList就有利于节约内存空间。")]),s._v(" "),t("h4",{attrs:{id:"linkedlist-arraylist"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#linkedlist-arraylist"}},[s._v("#")]),s._v(" linkedlist& ArrayList")]),s._v(" "),t("p",[s._v("ArrayList 采用的是数组形式来保存对象的，这种方式将对象放在连续的位置中，所以最大的缺点就是插入删除时非常麻烦")]),s._v(" "),t("p",[s._v("LinkedList 采用的将对象存放在独立的空间中，而且在每个空间中还保存下一个链接的索引 但是缺点就是查找非常麻烦 要丛第一个索引开始")]),s._v(" "),t("h3",{attrs:{id:"多线程实现方式thread和runnable的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#多线程实现方式thread和runnable的区别"}},[s._v("#")]),s._v(" 多线程实现方式Thread和Runnable的区别？")]),s._v(" "),t("h4",{attrs:{id:"线程实现介绍"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#线程实现介绍"}},[s._v("#")]),s._v(" 线程实现介绍")]),s._v(" "),t("p",[s._v("在java中可有两种方式实现多线程，一种是继承Thread类，一种是实现Runnable接口；")]),s._v(" "),t("p",[s._v("Thread类是在java.lang包中定义的。一个类只要继承了Thread类同时覆写了本类中的run()方法就可以实现多线程操作了，但是一个类只能继承一个父类，这是此方法的局限。")]),s._v(" "),t("p",[s._v("下面看例子：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("thread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("super")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程开始："')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('",i="')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("thread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ThreadDemo01")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt1"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt2"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程b"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        mt1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        mt2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br")])]),t("p",[s._v("但是，此时结果很有规律，先第一个对象执行，然后第二个对象执行，并没有相互运行。在JDK的文档中可以发现，"),t("strong",[s._v("一旦调用start()方法，则会通过JVM找到run()方法")]),s._v("。下面启动start()方法启动线程：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("thread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ThreadDemo01")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt1"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt2"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程b"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\tmt1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\tmt2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("p",[s._v("这样程序可以正常完成交互式运行。那么为啥非要使用start();方法启动多线程呢？\n在JDK的安装路径下，src.zip是全部的java源程序，通过此代码找到Thread中的start()方法的定义，可以发现此方法中使用了"),t("strong",[s._v("private native void start0()")]),s._v(";")]),s._v(" "),t("p",[s._v("其中"),t("strong",[s._v("native关键字")]),s._v("表示可以调用操作系统的底层函数，那么这样的技术成为JNI技术（java Native Interface）")]),s._v(" "),t("h4",{attrs:{id:"runnable接口"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#runnable接口"}},[s._v("#")]),s._v(" Runnable接口")]),s._v(" "),t("p",[s._v("在实际开发中一个多线程的操作很少使用Thread类，而是通过Runnable接口完成。")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("interface")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Runnable")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("例子：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("runnable"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("implements")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Runnable")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    \n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程开始："')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('",i="')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])]),t("p",[s._v("但是在使用Runnable定义的子类中没有start()方法，只有Thread类中才有。此时观察Thread类，有一个构造方法：public Thread(Runnable targer)此构造方法接受Runnable的子类实例，也就是说可以通过Thread类来启动Runnable实现的多线程。（start()可以协调系统的资源）：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("runnable"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("runnable"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ThreadDemo01")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt1"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt2"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"线程b"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mt1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mt2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])]),t("p",[s._v("两种实现方式的区别和联系：")]),s._v(" "),t("p",[s._v("在程序开发中只要是多线程肯定永远以实现Runnable接口为主，因为实现Runnable接口相比继承Thread类有如下好处：")]),s._v(" "),t("blockquote",[t("ul",[t("li",[s._v("避免点继承的局限，一个类可以继承多个接口。")]),s._v(" "),t("li",[s._v("适合于资源的共享")])])]),s._v(" "),t("p",[s._v("以卖票程序为例，通过Thread类完成：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dff")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" ticket"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ticket"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"卖票：ticket"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ticket"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    \t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("p",[s._v("下面通过三个线程对象，同时卖票：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dff")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ThreadTicket")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt1"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt2"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt3"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        mt1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//每个线程都各卖了10张，共卖了30张票")]),s._v("\n        mt2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//但实际只有10张票，每个线程都卖自己的票")]),s._v("\n        mt3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//没有达到资源共享")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])]),t("p",[s._v("实际只有10张表，但是由于余票数量（ticket）没有变量共享，所以卖出了30张。")]),s._v(" "),t("p",[s._v("如果用Runnable就可以实现"),t("strong",[s._v("资源共享")]),s._v("，下面看例子：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("runnable")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("implements")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Runnable")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" ticket "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ticket "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"卖票：ticket"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ticket"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n     \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("demo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("runnable")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RunnableTicket")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),s._v(" mt "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//同一个mt，但是在Thread中就不可以，如果用同一")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//个实例化对象mt，就会出现异常")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("start")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br")])]),t("p",[s._v("虽然现在程序中有三个线程，但是一共卖了10张票，也就是说使用"),t("strong",[s._v("Runnable实现多线程可以达到资源共享目的")]),s._v("。")]),s._v(" "),t("h3",{attrs:{id:"一个hadoop环境-整合了hbase和hive-是否有必要给hdfs和hbase都分别配置压缩策略-请给出对压缩策略的建议。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一个hadoop环境-整合了hbase和hive-是否有必要给hdfs和hbase都分别配置压缩策略-请给出对压缩策略的建议。"}},[s._v("#")]),s._v(" 一个HADOOP环境，整合了HBASE和HIVE，是否有必要给HDFS和HBASE都分别配置压缩策略？请给出对压缩策略的建议。")]),s._v(" "),t("p",[s._v("hdfs在存储的时候不会将数据进行压缩，如果想进行压缩，我们可以在向 hdfs上传数据的时候进行压缩。")]),s._v(" "),t("h4",{attrs:{id:"_1-采用压缩流"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-采用压缩流"}},[s._v("#")]),s._v(" 1. 采用压缩流")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//压缩文件")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("compress")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" codecClassName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throws")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Exception")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Class")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" codecClass "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("forName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("codecClassName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Configuration")]),s._v(" conf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Configuration")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileSystem")]),s._v(" fs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileSystem")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CompressionCodec")]),s._v(" codec "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CompressionCodec")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ReflectionUtils")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("newInstance")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("codecClass"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//指定压缩文件路径")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FSDataOutputStream")]),s._v(" outputStream "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" fs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Path")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/user/hadoop/text.gz"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//指定要被压缩的文件路径")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FSDataInputStream")]),s._v(" in "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" fs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("open")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Path")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/user/hadoop/aa.txt"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//创建压缩输出流")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CompressionOutputStream")]),s._v(" out "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" codec"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("createOutputStream")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outputStream"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOUtils")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("copyBytes")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOUtils")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("closeStream")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOUtils")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("closeStream")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br")])]),t("h4",{attrs:{id:"_2-采用序列化文件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-采用序列化文件"}},[s._v("#")]),s._v(" 2.采用序列化文件")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("testSeqWrite")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throws")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Exception")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    \n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Configuration")]),s._v(" conf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Configuration")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建配置信息")]),s._v("\n\tconf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"fs.default.name"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hdfs://master:9000"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// hdfs默认路径")]),s._v("\n\tconf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop.job.ugi"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop,hadoop"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 用户和组信息")]),s._v("\n    \n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" uriin "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hdfs://master:9000/ceshi2/"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 文件路径")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileSystem")]),s._v(" fs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileSystem")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("URI"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("uriin"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建filesystem")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Path")]),s._v(" path "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Path")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hdfs://master:9000/ceshi3/test.seq"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 文件名")]),s._v("\n    \n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IntWritable")]),s._v(" k "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IntWritable")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// key，相当于 int")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),s._v(" v "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// value，相当于 String")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SequenceFile"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Writer")]),s._v(" w "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SequenceFile")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("createWriter")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" path"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" v"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建 writer")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 循环添加")]),s._v("\n        k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        v"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"abcd"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        w"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("append")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" v"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    \n\tw"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOUtils")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("closeStream")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 关闭的时候 flush")]),s._v("\n\tfs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br")])]),t("p",[s._v("hbase为列存数据库，本身存在压缩机制，所以无需设计。")]),s._v(" "),t("h3",{attrs:{id:"❤️简述hbase性能优化的思路"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️简述hbase性能优化的思路"}},[s._v("#")]),s._v(" ❤️简述Hbase性能优化的思路")]),s._v(" "),t("ol",[t("li",[s._v("在库表设计的时候，尽量考虑rowkey和columnfamily的特性")]),s._v(" "),t("li",[s._v("进行hbase集群的调优：见hbase调优")])]),s._v(" "),t("h3",{attrs:{id:"简述hbase-filter的实现原理是什么-结合实际项目经验-写出几个使用filter的场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#简述hbase-filter的实现原理是什么-结合实际项目经验-写出几个使用filter的场景"}},[s._v("#")]),s._v(" 简述Hbase filter的实现原理是什么？结合实际项目经验，写出几个使用filter的场景")]),s._v(" "),t("p",[s._v("hbase的filter是通过scan设置的，所以是基于scan的查询结果进行过滤")]),s._v(" "),t("p",[s._v("1、 在进行订单开发的时候，我们使用 rowkeyfilter过滤出某个用户的所有订单。\n2、 在进行云笔记开发时，我们使用 rowkey过滤器进行redis数据的恢复。")]),s._v(" "),t("h3",{attrs:{id:"rowkey的后缀匹配怎么实现-例如rowkey是yyyymmdd-userid形式-如userid为条件查询数据-怎么实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rowkey的后缀匹配怎么实现-例如rowkey是yyyymmdd-userid形式-如userid为条件查询数据-怎么实现"}},[s._v("#")]),s._v(" ROWKEY的后缀匹配怎么实现？例如ROWKEY是yyyyMMDD-UserID形式，如UserID为条件查询数据，怎么实现")]),s._v(" "),t("p",[s._v("使用rowkey过滤器实现")]),s._v(" "),t("h3",{attrs:{id:"简述hive中的虚拟列作用是什么-使用它的注意事项"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#简述hive中的虚拟列作用是什么-使用它的注意事项"}},[s._v("#")]),s._v(" 简述Hive中的虚拟列作用是什么，使用它的注意事项")]),s._v(" "),t("div",{staticClass:"language-properties line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-properties"}},[t("code",[s._v("Hive提供了三个虚拟列：\nINPUT__FILE__NAME\nBLOCK__OFFSET__INSIDE__FILE\nROW__OFFSET__INSIDE__BLOCK\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("但ROW__OFFSET__INSIDE__BLOCK默认是不可用的，需要设置")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("hive.exec.rowoffset为 true才可以。可以用来排查有问题的输入数据。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("INPUT__FILE__NAME,")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("mapper任务的输出文件名。")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("BLOCK__OFFSET__INSIDE__FILE,")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("当前全局文件的偏移量。对于块压缩文件，就是当前块的文件偏移量，即当前块的 第一个字节在文件中的偏移量。")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("hive>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("SELECT INPUT__FILE__NAME, BLOCK__OFFSET__INSIDE__FILE, line")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("FROM hive_text WHERE line LIKE '%hive%' LIMIT 2;")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("har")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("//file/user/hive/warehouse/hive_text/folder=docs/")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("data.har/user/hive/warehouse/hive_text/folder")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("docs/README.txt 2243")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("har")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("//file/user/hive/warehouse/hive_text/folder=docs/")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token key attr-name"}},[s._v("data.har/user/hive/warehouse/hive_text/folder")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token value attr-value"}},[s._v("docs/README.txt 3646")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])]),t("h3",{attrs:{id:"如果要存储海量的小文件-大小都是几百k-几m-请简述自己的设计方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如果要存储海量的小文件-大小都是几百k-几m-请简述自己的设计方案"}},[s._v("#")]),s._v(" 如果要存储海量的小文件（大小都是几百K~几M），请简述自己的设计方案")]),s._v(" "),t("ol",[t("li",[s._v("将小文件达成har文件存储")]),s._v(" "),t("li",[s._v("将小文件序列化到hdfs中")])]),s._v(" "),t("h3",{attrs:{id:"有两个文本文件-文件中的数据按行存放-请编写mapreduce程序-找到两个文件中彼此不相同的行"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#有两个文本文件-文件中的数据按行存放-请编写mapreduce程序-找到两个文件中彼此不相同的行"}},[s._v("#")]),s._v(" 有两个文本文件，文件中的数据按行存放，请编写MapReduce程序，找到两个文件中彼此不相同的行")]),s._v(" "),t("p",[s._v("写个mapreduce链用依赖关系，一共三个mapreduce，第一个处理第一个文件，第二个处理第二个文件，第三个处理前两个的输出结果。第一个mapreduce将文件去重，第二个mapreduce也将文件去重，第三个做wordcount，wordcount为1的结果就是不同的。")]),s._v(" "),t("h3",{attrs:{id:"mapreduce找共同朋友"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce找共同朋友"}},[s._v("#")]),s._v(" mapreduce找共同朋友")]),s._v(" "),t("p",[s._v("mapreduce找共同朋友，数据格式如下：")]),s._v(" "),t("ol",[t("li",[s._v("A B C D E F")]),s._v(" "),t("li",[s._v("B A C D E")]),s._v(" "),t("li",[s._v("C A B E")]),s._v(" "),t("li",[s._v("D A B E")]),s._v(" "),t("li",[s._v("E A B C D")]),s._v(" "),t("li",[s._v("F A")])]),s._v(" "),t("p",[s._v("第一个字母表示本人，其他的是他的朋友，找出有共同朋友的人，和共同朋友是谁。")]),s._v(" "),t("p",[s._v("思路：例如A，他的朋友是B\\C\\D\\E\\F，那么BC的共同朋友就是A。所以将BC作为key，将A作为value，在map端输出即可！其他的朋友循环处理。")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("io"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOException")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Set")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringTokenizer")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("java"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TreeSet")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Configuration")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Path")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("io"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mapreduce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Job")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mapreduce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Mapper")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mapreduce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Reducer")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mapreduce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Mapper")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Context")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mapreduce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("input"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileInputFormat")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mapreduce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("output"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileOutputFormat")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token import"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hadoop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GenericOptionsParser")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FindFriend")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ChangeMapper")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Mapper")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Override")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("map")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Context")]),s._v(" context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throws")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InterruptedException")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringTokenizer")]),s._v(" itr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringTokenizer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("toString")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),s._v(" owner "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Set")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" set "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TreeSet")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        owner"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("itr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("nextToken")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("itr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hasMoreTokens")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            set"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("add")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("itr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("nextToken")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//从key中查找共同朋友")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" friends "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("set"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("size")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        friends "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" set"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("toArray")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("friends"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("friends"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" j"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("friends"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" outputkey "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" friends"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("friends"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("write")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outputkey"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("owner"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FindReducer")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Reducer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("reduce")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Iterable")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" values"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Context")]),s._v(" context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throws")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InterruptedException")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" commonfriends "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n       \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//输出共同朋友")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),s._v(" val "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" values"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("commonfriends "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                commonfriends "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("toString")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                commonfriends "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" commonfriends"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('":"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("toString")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n        context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("write")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("commonfriends"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throws")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InterruptedException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ClassNotFoundException")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Configuration")]),s._v(" conf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Configuration")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" otherArgs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GenericOptionsParser")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getRemainingArgs")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("otherArgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("err"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"args error"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("exit")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Job")]),s._v(" job "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Job")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"word count"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setJarByClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FindFriend")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setMapperClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ChangeMapper")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setCombinerClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FindReducer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setReducerClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FindReducer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setOutputKeyClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setOutputValueClass")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Text")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" otherArgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    \t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileInputFormat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("addInputPath")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Path")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("otherArgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("FileOutputFormat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setOutputPath")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Path")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("otherArgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("otherArgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("exit")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("job"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("waitForCompletion")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br"),t("span",{staticClass:"line-number"},[s._v("78")]),t("br"),t("span",{staticClass:"line-number"},[s._v("79")]),t("br"),t("span",{staticClass:"line-number"},[s._v("80")]),t("br"),t("span",{staticClass:"line-number"},[s._v("81")]),t("br"),t("span",{staticClass:"line-number"},[s._v("82")]),t("br"),t("span",{staticClass:"line-number"},[s._v("83")]),t("br")])]),t("p",[s._v("结果：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.")]),s._v(" AB "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("C")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("D")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.")]),s._v(" AC "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),s._v(" AD "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("E")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.")]),s._v(" AE "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("C")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("D")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.")]),s._v(" BC "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("E")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.")]),s._v(" BD "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("E")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.")]),s._v(" BE "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("C")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("D")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8.")]),s._v(" BF "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9.")]),s._v(" CD "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.")]),s._v(" CE "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11.")]),s._v(" CF "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.")]),s._v(" DE "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13.")]),s._v(" DF "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14.")]),s._v(" EF "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("h3",{attrs:{id:"基站逗留时间合并"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基站逗留时间合并"}},[s._v("#")]),s._v(" 基站逗留时间合并")]),s._v(" "),t("p",[s._v("使用Hive或自定义MR实现如下逻辑")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("product_no")]),s._v(" "),t("th",[s._v("lac_id")]),s._v(" "),t("th",[s._v("moment")]),s._v(" "),t("th",[s._v("start_time")]),s._v(" "),t("th",[s._v("user_id")]),s._v(" "),t("th",[s._v("county_id")]),s._v(" "),t("th",[s._v("staytime")]),s._v(" "),t("th",[s._v("city_id")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("13429100031")]),s._v(" "),t("td",[s._v("22554")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:55:19.151754088")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("282")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100082")]),s._v(" "),t("td",[s._v("22540")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:58:20.152622488")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("270")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100082")]),s._v(" "),t("td",[s._v("22691")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:56:37.149593624")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("103")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100087")]),s._v(" "),t("td",[s._v("22750")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:56:51.139539816")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("220")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100087")]),s._v(" "),t("td",[s._v("22540")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:55:45.150276800")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("66")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100082")]),s._v(" "),t("td",[s._v("22540")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:55:38.140225200")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("133")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100140")]),s._v(" "),t("td",[s._v("26642")]),s._v(" "),t("td",[s._v("9")]),s._v(" "),t("td",[s._v("2013-03-11 09:02:19.151754088")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("18")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100082")]),s._v(" "),t("td",[s._v("22691")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:57:32.151754088")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("287")]),s._v(" "),t("td",[s._v("571")])])])]),s._v(" "),t("p",[t("strong",[s._v("字段解释")])]),s._v(" "),t("p",[s._v("product_no：用户手机号；")]),s._v(" "),t("p",[s._v("lac_id：用户所在基站；")]),s._v(" "),t("p",[s._v("start_time：用户在此基站的开始时间；")]),s._v(" "),t("p",[s._v("staytime：用户在此基站的逗留时间。")]),s._v(" "),t("p",[t("strong",[s._v("需求")])]),s._v(" "),t("p",[s._v("根据 lac_id 和 start_time 知道用户当时的位置，根据 staytime 知道用户各个基站的逗留时长。根据轨迹合并连续基站的staytime。\n最终得到每一个用户按时间排序在每一个基站驻留时长。")]),s._v(" "),t("p",[t("strong",[s._v("期望：")])]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("13429100082")]),s._v(" "),t("th",[s._v("22540")]),s._v(" "),t("th",[s._v("8")]),s._v(" "),t("th",[s._v("2013-03-11 08:58:20.152622488")]),s._v(" "),t("th",[s._v("571")]),s._v(" "),t("th",[s._v("571")]),s._v(" "),t("th",[s._v("270")]),s._v(" "),t("th",[s._v("571")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("13429100082")]),s._v(" "),t("td",[s._v("22691")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:56:37.149593624")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("103")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100082")]),s._v(" "),t("td",[s._v("22540")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:55:38.140225200")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("133")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100087")]),s._v(" "),t("td",[s._v("22705")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:56:51.139539816")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("220")]),s._v(" "),t("td",[s._v("571")])]),s._v(" "),t("tr",[t("td",[s._v("13429100087")]),s._v(" "),t("td",[s._v("22540")]),s._v(" "),t("td",[s._v("8")]),s._v(" "),t("td",[s._v("2013-03-11 08:55:45.150276800")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("571")]),s._v(" "),t("td",[s._v("66")]),s._v(" "),t("td",[s._v("571")])])])]),s._v(" "),t("p",[t("strong",[s._v("思路：")]),s._v("\n将数据导入hive表中，查询时，用电话号码和时间排序即可！")]),s._v(" "),t("h3",{attrs:{id:"脚本替换"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#脚本替换"}},[s._v("#")]),s._v(" 脚本替换")]),s._v(" "),t("p",[s._v("请随意使用各种类型的脚本语言实现: 批量将指定目录下的所有文件中的"),t("code",[s._v("$HADOOP_HOOME$/home/ocetl/app/hadoop")]),s._v("替换成"),t("code",[s._v("/home/ocetl/app/hadoop")])]),s._v(" "),t("p",[s._v("脚本：随意命名为aaa.sh")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token shebang important"}},[s._v("#!/bin/bash")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ls")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("read")]),s._v(" line\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sed")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'s,\\$HADOOP_HOME\\$,\\/home\\/aa,g'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$1")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$line")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$1")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$line")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("脚本执行命令：替换\n/home/hadoop/test/下的所有文件")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("./aaa.sh /home/hadoop/test/\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h3",{attrs:{id:"一键执行"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一键执行"}},[s._v("#")]),s._v(" 一键执行")]),s._v(" "),t("p",[s._v("假设有 10 台主机，H1 到 H10，在开启 SSH 互信的情况下，编写一个或多个脚本实现在所有的远程主机上执行脚本的功能")]),s._v(" "),t("p",[s._v('例如：runRemoteCmd.sh "ls-l"')]),s._v(" "),t("p",[s._v("脚本：\nvi runRemoteCmd.sh")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token shebang important"}},[s._v("#!/bin/bash")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$1")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ssh")]),s._v(" q hadoop@slave1 "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$1")]),s._v('"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ssh")]),s._v(" q hadoop@slave2 "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$1")]),s._v('"')]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("执行命令")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("./runRemoteCmd.sh "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"ls l"')]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h2",{attrs:{id:"面试简答"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试简答"}},[s._v("#")]),s._v(" 面试简答")]),s._v(" "),t("ol",[t("li",[t("h4",{attrs:{id:"❤️讲解一下-mapreduce-的一些基本流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️讲解一下-mapreduce-的一些基本流程"}},[s._v("#")]),s._v(" ❤️讲解一下 MapReduce 的一些基本流程")]),s._v(" "),t("p",[s._v("任务提交流程，任务运行流程")])]),s._v(" "),t("li",[t("p",[s._v("你们数据库怎么导入 hive 的 ,有没有出现问题使用")]),s._v(" "),t("p",[s._v("sqoop导入，我们公司的数据库中设计了 text字段，导致导入的时候出现了缓存不够的情况（见\n云笔记），开始解决起来感觉很棘手，后来查看了 sqoop的文档，加上了 limit属性，解决了。")])]),s._v(" "),t("li",[t("p",[s._v("公司技术选型可能利用 storm 进行实时计算 ,讲解一下 storm")]),s._v(" "),t("p",[s._v("从storm的应用，代码书写，运行机制讲")])]),s._v(" "),t("li",[t("p",[s._v("问你 java 集合类的数据结构 ,比如 hashmap\n看java面试宝典")])]),s._v(" "),t("li",[t("p",[s._v("问你知不知道 concurrent 包下的东西 ,例如 concurrenthashmap\n看java面试宝典")])]),s._v(" "),t("li",[t("p",[s._v("公司最近主要在自然语言学习去开发 ,有 没有接触过\n没有用过")])])]),s._v(" "),t("h2",{attrs:{id:"面试问题1"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试问题1"}},[s._v("#")]),s._v(" 面试问题1")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("从前到后从你教育背景 (学过哪些课 )到各个项目你负责的模块 ,问的很细 (本以为他是物理学博士 ,但是所有的技术都懂 )")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("hadoop 的 namenode 宕机 ,怎么解决")])])])]),s._v(" "),t("p",[s._v("先分析宕机后的损失，宕机后直接导致client无法访问，内存中的元数据丢失，但是硬盘中的元数据应该还存在，如果只是节点挂了，重启即可，如果是机器挂了，重启机器后看节点是否能重启，不能重启就要找到原因修复了。但是最终的解决方案应该是在设计集群的初期就考虑到这个问题，做namenode的 HA。")]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[t("p",[s._v("一个 datanode 宕机 ,怎么一个流程恢复\nDatanode宕机了后，如果是短暂的宕机，可以实现写好脚本监控，将它启动起来。如果是长时间宕机了，那么 datanode上的数据应该已经被备份到其他机器了，那这台 datanode就是一台新的 datanode了，删除他的所有数据文件和状态文件，重新启动。")])]),s._v(" "),t("li",[t("p",[s._v("Hbase 的特性 ,以及你怎么去设计 rowkey 和 columnFamily ,怎么去建一个 table\n因为hbase是列式数据库，列非表 schema的一部分，所以在设计初期只需要考虑 rowkey 和columnFamily即可， rowkey有位置相关性，所以如果数据是练习查询的，最好对同类数据加一个前缀，而每个 columnFamily实际上在底层是一个文件，那么文件越小，查询越快，所以讲经常一起查询的列设计到一个列簇，但是列簇不宜过多。")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("❤️Redis,传统数据库 ,hbase,hive 每个之间的区别 (问的非常细 )")]),s._v("\nRedis是缓存，围绕着内存和缓存说\nHbase是列式数据库，存在 hdfs上，围绕着数据量来说\nHive是数据仓库，是用来分析数据的，不是增删改查数据的。")])]),s._v(" "),t("li",[t("p",[s._v("公司之后倾向用 spark 开发 ,你会么 (就用 java代码去写 )")]),s._v(" "),t("p",[s._v("会，spark使用 scala开发的，在 scala中可以随意使用 jdk的类库，可以用 java开发，但是最好用原生的 scala开发，兼容性好， scala更灵活。")])])]),s._v(" "),t("h2",{attrs:{id:"面试问题2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试问题2"}},[s._v("#")]),s._v(" 面试问题2")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("笔试 : java基础 (基本全忘 ,做的很烂 ,复习大数据连单例都忘了怎么写 )")]),s._v(" "),t("p",[s._v("复习java面试宝典")])]),s._v(" "),t("li",[t("p",[s._v("开始介绍项目 ,直接用大数据项目介绍 ,项目经理也懂大数据")])]),s._v(" "),t("li",[t("p",[s._v("Mapreduce一些流程 ,经过哪些步骤Map combiner partition sort copy sort grouping reduce")]),s._v(" "),t("div",{staticClass:"language-sequence line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("Map --\x3ecombiner:\ncombiner --\x3epartition:\npartition --\x3esort:\nsort --\x3ecopy:\ncopy --\x3esort:\nsort --\x3egrouping: \ngrouping--\x3ereduce:\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("❤️说下对 hadoop 的一些理解 ,包括哪些组件")]),s._v("\n详谈hadoop的应用，包括的组件分为三类，分别说明 hdfs yarn mapreduce")])]),s._v(" "),t("li",[t("p",[s._v("详细讲解下你流式实时计算的项目部署以及收集的结果情况\n讲解storm集群的部署方案，项目的大小，使用的 worker数，数据收集在 hbase或者 hdfs，好处是什\n么")])]),s._v(" "),t("li",[t("p",[s._v("你的数据库是不是很大么 ,有没有分表 ,分区 ,你是怎么实现的")]),s._v(" "),t("p",[s._v("数据库的分表在设计初期是按照月份进行拆分的，不同的月份查询不同的表。分区没弄过。")])]),s._v(" "),t("li",[t("p",[s._v("开始问 java的一些东西 (从各种框架原理到各种复杂 SQL)")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("😋多线程 ,并发 ,垃圾回收机制 ,数据结构 (问这些 ,基本觉得看你是不是高级程序员了 )")])]),s._v(" "),t("p",[s._v("多线程要知道操作方式，线程安全的锁，并且要知道lock锁\n垃圾回收机制需要详细了解（见云笔记），主要从内存划分，垃圾回收主要的工作区域，垃圾回收器的\n种类，各有什么优缺点，用在哪里合适。\n数据结构基本的要知道，复杂的参考相关的书籍。")])])]),s._v(" "),t("h2",{attrs:{id:"面试问题3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试问题3"}},[s._v("#")]),s._v(" 面试问题3")]),s._v(" "),t("ol",[t("li",[t("p",[t("strong",[s._v("BI小组的 3个年轻学生一起技术面试 (一个是南开博士）")])])]),s._v(" "),t("li",[t("p",[s._v("数据量多少 ,集群规模多大 ,型号\n一般中型的电商或者互联网企业，日志量每天在200 500M左右，集群规模在 30 50台左右，机器一 般为 dell的 2000左右的服务器，型号不定。")]),s._v(" "),t("p",[s._v("大型的互联网公司据网上资料显示，日志量在GP PB不等，集群规模在 500 4000不等，甚至更多，机器型号不确定。")])]),s._v(" "),t("li",[t("p",[s._v("项目 ,mapreduce")]),s._v(" "),t("p",[s._v("介绍整个mapreduce项目流程，数据采集 数据聚合 数据分析 数据展示等")])]),s._v(" "),t("li",[t("p",[s._v("实时流式计算框架 ,几个人 ,多长时间 ,细节问题 ,包括讲 flume ,kafka ,storm 的各个的组件组成 ,你负责哪一块 ,如果需要你搭建你可以完成么 ?")])]),s._v(" "),t("li",[t("p",[s._v("你觉得 spark 可以完全替代 hadoop 么 ?")])])]),s._v(" "),t("h2",{attrs:{id:"面试问题4"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试问题4"}},[s._v("#")]),s._v(" 面试问题4")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("一些传统的 hadoop 问题 ,mapreduce 他就问 shuffle 阶段 ,你怎么理解的\nShuffle意义在于将不同 map处理后的数据进行合理分配，让 reduce处理，从而产生了排序、分区。")])]),s._v(" "),t("li",[t("p",[s._v("Mapreduce 的 map 数量 和 reduce 数量 怎么确定 ,怎么配置\nMap无法配置，reduce随便配置")])]),s._v(" "),t("li",[t("p",[s._v("唯一难住我的是他说实时计算 ,storm 如果碰上了复杂逻辑 ,需要算很长的时间 ,你怎么去优化\n拆分复杂的业务到多个\nbolt中，这样可以利用 bolt的 tree将速度提升")])]),s._v(" "),t("li",[t("p",[s._v("Hive 你们用的是外部表还是内部表 ,有没有写过 UDF(当然吹自己写过了 ),hive 的版本\n外部表，udf udaf等， hive版本为 1.0")])]),s._v(" "),t("li",[t("p",[s._v("Hadoop 的版本\n如果是\n1.0版本就说 1.2，如果是 2.0版本，就说 2.6或者 2.7\n1.2为官方稳定版本， 2.7为官方稳定版本。\nApache Hadoop 2.7.1于美国时间 2015年 07月 06日正式发布，本版本属于稳定版本，是自 Hadoop 2.6.0以来又一个稳定版，同时也 是 Hadoop 2.7.x版本线的第一个稳定版本，也是 2.7版本线的维护版本，变化不大，主要是修复了一些比较严重的 Bug")])]),s._v(" "),t("li",[t("p",[s._v("实时流式计算 的结果内容有哪些 ,你们需要统计出来么 (我就说 highchart展示 )\n简单介绍日志监控、风控等结果内容，统计出来显示在报表或者邮件中。")])]),s._v(" "),t("li",[t("p",[s._v("开始问 java相关 ,包括 luecne,solr(倒排索引的原理 ),框架呀 ,redis呀。")])])]),s._v(" "),t("h2",{attrs:{id:"❤️京东商城-大数据面试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#❤️京东商城-大数据面试"}},[s._v("#")]),s._v(" ❤️京东商城-大数据面试")]),s._v(" "),t("h4",{attrs:{id:"java篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#java篇"}},[s._v("#")]),s._v(" java篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("JVM,GC(算法，新生代，老年代)，JVM结构")])]),s._v(" "),t("li",[t("p",[s._v("hashcode，hashMap，list，hashSet，equals（结构原理），A extends B（类的加载顺序）")]),s._v(" "),t("p",[s._v("1.父类静态代码块； 2.子类静态代码块； 3.父类非静态代码块； 4.父类构造函数； 5.子类非静态代码块； 6.子类构造函数；")])]),s._v(" "),t("li",[t("p",[s._v("多线程，主线程，次线程，唤醒，睡眠")]),s._v(" "),t("p",[s._v("略")])]),s._v(" "),t("li",[t("p",[s._v("常见算法：冒泡算法、排序算法，二分查找，时间复杂度")]),s._v(" "),t("p",[s._v("略")])])]),s._v(" "),t("h4",{attrs:{id:"flume篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flume篇"}},[s._v("#")]),s._v(" Flume篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("数据怎么采集到Kafka，实现方式 使用官方提供的flumeKafka插件，插件的实现方式是自定义了flume的sink，将数据从channle中取出，通过kafka的producer写入到kafka中，可以自定义分区等。")])]),s._v(" "),t("li",[t("p",[s._v("flume管道内存，flume宕机了数据丢失怎么解决")]),s._v(" "),t("ol",[t("li",[s._v("Flume的channel分为很多种，可以将数据写入到文件")]),s._v(" "),t("li",[s._v("防止非首个agent宕机的方法数可以做集群或者主备")])])]),s._v(" "),t("li",[t("p",[s._v("flume配置方式，flume集群（问的很详细）")]),s._v(" "),t("p",[s._v("Flume的配置围绕着source、channel、sink叙述，flume的集群是做在agent上的，而非机器上。")])]),s._v(" "),t("li",[t("p",[s._v("flume不采集Nginx日志，通过Logger4j采集日志，优缺点是什么？")]),s._v(" "),t("p",[s._v("优点：Nginx的日志格式是固定的，但是缺少sessionid，通过logger4j采集的日志是带有sessionid的，而session可以通过redis共享，保证了集群日志中的同一session落到不同的tomcat时，sessionId还是一样的，而且logger4j的方式比较稳定，不会宕机。")]),s._v(" "),t("p",[s._v("缺点：不够灵活，logger4j的方式和项目结合过于紧密，而flume的方式比较灵活，拔插式比较好，不会影响项目性能。")])]),s._v(" "),t("li",[t("p",[s._v("flume和kafka采集日志区别，采集日志时中间停了，怎么记录之前的日志。")]),s._v(" "),t("p",[s._v("Flume采集日志是通过流的方式直接将日志收集到存储层，而kafka试讲日志缓存在kafka集群，待后期可以采集到存储层。 Flume采集中间停了，可以采用文件的方式记录之前的日志，而kafka是采用offset的方式记录之前的日志。")])])]),s._v(" "),t("h4",{attrs:{id:"kafka篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka篇"}},[s._v("#")]),s._v(" Kafka篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("容错机制")]),s._v(" "),t("p",[s._v("分区备份，存在主备partition")])]),s._v(" "),t("li",[t("p",[s._v("同一topic不同partition分区")]),s._v(" "),t("p",[s._v("？？？？")])]),s._v(" "),t("li",[t("p",[s._v("kafka数据流向")]),s._v(" "),t("p",[s._v("Producer → leader partition → follower partition(半数以上) →consumer")])]),s._v(" "),t("li",[t("p",[s._v("kafka+spark-streaming结合丢数据怎么解决？")]),s._v(" "),t("p",[s._v("spark streaming从1.2开始提供了数据的零丢失，想享受这个特性，需要满足如下条件：")]),s._v(" "),t("ol",[t("li",[s._v("数据输入需要可靠的sources和可靠的receivers")]),s._v(" "),t("li",[s._v("应用metadata必须通过应用driver checkpoint")]),s._v(" "),t("li",[s._v("WAL（write ahead log）")])])]),s._v(" "),t("li",[t("p",[s._v("​\t"),t("strong",[s._v("可靠的 sources和 receivers")])])])]),s._v(" "),t("p",[s._v("​\tspark streaming可以通过多种方式作为数据sources（包括kafka），输入数据通过receivers接收，通过replication存储于spark中（为了faultolerance，默认复制到两个spark executors），如果数据复制完成，receivers可以知道（例如kafka中更新offsets到zookeeper中）。这样当receivers在接收数据过程中crash掉，不会有数据丢失，receivers没有复制的数据，当receiver恢复后重新接收。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/jacksu/utils4s/master/spark-knowledge/images/spark-streaming-kafka/spark-reliable-source-reliable-receiver.png",alt:"img"}})]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[t("strong",[s._v("metadata checkpoint")])])]),s._v(" "),t("p",[s._v("​\t可靠的sources和receivers，可以使数据在receivers失败后恢复，然而在driver失败后恢复是比较复杂的，一种方法是通过checkpoint metadata到HDFS或者S3。metadata包括：")]),s._v(" "),t("ul",[t("li",[s._v("configuration")]),s._v(" "),t("li",[s._v("code")]),s._v(" "),t("li",[s._v("一些排队等待处理但没有完成的 RDD（仅仅是 metadata，而不是 data")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/jacksu/utils4s/master/spark-knowledge/images/spark-streaming-kafka/spark-metadata-checkpointing.png",alt:"img"}})]),s._v(" "),t("p",[s._v("这样当driver失败时，可以通过metadata checkpoint，重构应用程序并知道执行到那个地方。")]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[t("p",[t("strong",[s._v("数据可能丢失的场景")]),s._v("\n可靠的sources和receivers，以及metadata checkpoint也不可以保证数据的不丢失，例如：")]),s._v(" "),t("ol",[t("li",[s._v("两个 executor得到计算数据，并保存在他们的内存中")]),s._v(" "),t("li",[s._v("receivers知道数据已经输入")]),s._v(" "),t("li",[s._v("executors开始计算数据")]),s._v(" "),t("li",[s._v("driver突然失败")]),s._v(" "),t("li",[s._v("driver失败，那么 executors都会被 kill掉")]),s._v(" "),t("li",[s._v("因为 executor被 kill掉，那么他们内存中得数据都会丢失，但是这些数据不再被处理")]),s._v(" "),t("li",[s._v("executor中的数据不可恢复")])])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("WAL")])]),s._v(" "),t("p",[s._v("为了避免上面情景的出现，spark streaming 1.2引入了WAL。所有接收的数据通过receivers写入HDFS或者S3中checkpoint目录，这样当driver失败后，executor中数据丢失后，可以通过checkpoint恢复。")])])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/jacksu/utils4s/master/spark-knowledge/images/spark-streaming-kafka/spark-wal.png",alt:"img"}})]),s._v(" "),t("ol",{attrs:{start:"5"}},[t("li",[t("strong",[s._v("At Least Once")])])]),s._v(" "),t("p",[s._v("尽管WAL可以保证数据零丢失，但是不能保证exactly-once，例如下面场景：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("Receivers接收完数据并保存到HDFS或S3")])]),s._v(" "),t("li",[t("p",[s._v("在更新offset前，receivers失败了")])])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/jacksu/utils4s/master/spark-knowledge/images/spark-streaming-kafka/spark-wall-at-least-once-delivery.png",alt:"img"}})]),s._v(" "),t("ul",[t("li",[s._v("Spark Streaming以为数据接收成功，但是Kafka以为数据没有接收成功，因为offset没有更新到zookeeper")]),s._v(" "),t("li",[s._v("随后receiver恢复了")]),s._v(" "),t("li",[s._v("从WAL可以读取的数据重新消费一次，因为使用的kafka High-Level消费API，从zookeeper中保存的offsets开始消费")])]),s._v(" "),t("ol",{attrs:{start:"6"}},[t("li",[t("strong",[s._v("WAL的缺点")])])]),s._v(" "),t("p",[s._v("通过上面描述，WAL有两个缺点：")]),s._v(" "),t("ul",[t("li",[s._v("降低了 receivers的性能，因为数据还要存储到 HDFS等分布式文件系统")]),s._v(" "),t("li",[s._v("对于一些 resources，可能存在重复的数据，比如 Kafka，在 Kafka中存在一份数据，在 Spark Streaming也存在一份（以 WAL的形式存储在 hadoop API兼容的文件系\n统中）")])]),s._v(" "),t("ol",{attrs:{start:"7"}},[t("li",[t("strong",[s._v("Kafka direct API")])])]),s._v(" "),t("p",[s._v("为了WAL的性能损失和exactly-once，spark streaming1.3中使用Kafka direct API。非常巧妙，Spark driver计算下个batch的offsets，指导executor消费对应的topics和partitions。消费Kafka消息，就像消费文件系统文件一样。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/jacksu/utils4s/master/spark-knowledge/images/spark-streaming-kafka/spark-kafka-direct-api.png",alt:"img"}})]),s._v(" "),t("ol",[t("li",[t("p",[s._v("不再需要kafka receivers，executor直接通过Kafka API消费数据")])]),s._v(" "),t("li",[t("p",[s._v("WAL不再需要，如果从失败恢复，可以重新消费")])]),s._v(" "),t("li",[t("p",[s._v("exactly-once得到了保证，不会再从WAL中重复读取数据")])]),s._v(" "),t("li",[t("p",[t("strong",[s._v("总结")])])])]),s._v(" "),t("p",[s._v("主要说的是spark streaming通过各种方式来保证数据不丢失，并保证exactly-once，每个版本都是spark streaming越来越稳定，越来越向生产环境使用发展。")]),s._v(" "),t("p",[s._v("5、kafka中存储目录data/dir.....topic1和topic2怎么存储的，存储结构，data.....目录下有多少个分区，每个分区的存储格式是什么样的？")]),s._v(" "),t("ol",[t("li",[s._v("topic是按照“主题名-分区”存储的 2.")]),s._v(" "),t("li",[s._v("分区个数由配置文件决定 3.")]),s._v(" "),t("li",[s._v("每个分区下最重要的两个文件是0000000000.log和000000.index，0000000.log以默认1G大小回滚。")])]),s._v(" "),t("h4",{attrs:{id:"hive篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive篇"}},[s._v("#")]),s._v(" Hive篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("hive partition分区")]),s._v(" "),t("p",[s._v("分区表，动态分区")])]),s._v(" "),t("li",[t("p",[s._v("insert into 和 override write区别？")]),s._v(" "),t("p",[s._v("insert into：将某一张表中的数据写到另一张表中")]),s._v(" "),t("p",[s._v("override write：覆盖之前的内容。")])]),s._v(" "),t("li",[t("p",[s._v("假如一个分区的数据主部错误怎么通过hivesql删除hdfs")]),s._v(" "),t("p",[s._v("alter table ptable drop partition (daytime='20140911',city='bj');")]),s._v(" "),t("p",[s._v("元数据，数据文件都删除，但目录daytime= 20140911还在")])])]),s._v(" "),t("h4",{attrs:{id:"storm篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#storm篇"}},[s._v("#")]),s._v(" Storm篇")]),s._v(" "),t("ol",[t("li",[s._v("开发流程，容错机制")])]),s._v(" "),t("p",[s._v("开发流程：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("写主类（设计spout和bolt的分发机制） 2.")])]),s._v(" "),t("li",[t("p",[s._v("写spout收集数据 3.")])]),s._v(" "),t("li",[t("p",[s._v("写bolt处理数据，根据数据量和业务的复杂程度，设计并行度。")]),s._v(" "),t("p",[s._v("容错机制：采用ack和fail进行容错，失败的数据重新发送。")])]),s._v(" "),t("li",[t("p",[s._v("storm和spark-streaming：为什么用storm不同spark-streaming")])]),s._v(" "),t("li",[t("p",[s._v("mr和spark区别，怎么理解spark-rdd")])])]),s._v(" "),t("p",[s._v("Mr是文件方式的分布式计算框架，是将中间结果和最终结果记录在文件中，map和reduce的数据分发也是在文件中。")]),s._v(" "),t("p",[s._v("spark是内存迭代式的计算框架，计算的中间结果可以缓存内存，也可以缓存硬盘，但是不是每一步计算都需要缓存的。")]),s._v(" "),t("p",[s._v("Spark-rdd是一个数据的分区记录集合………………")]),s._v(" "),t("ol",{attrs:{start:"4"}},[t("li",[s._v("sqoop命令")])]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("sqoop "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("import")]),s._v(" --connect jdbc:mysql://192.168.56.204:3306/sqoop --username hive --password hive --table jobinfo --target-dir /sqoop/test7 --inline-lob-limit "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16777216")]),s._v(" --fields-terminated-by "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\t'")]),s._v(" -m "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n\nsqoop create-hive-table --connect jdbc:mysql://192.168.56.204:3306/sqoop --table jobinfo --username hive --password hive --hive-table sqtest --fields-terminated-by "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[s._v("\\t")]),s._v('"')]),s._v(" --lines-terminated-by "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"'),t("span",{pre:!0,attrs:{class:"token entity",title:"\\n"}},[s._v("\\n")]),s._v('"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("h4",{attrs:{id:"redis篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis篇"}},[s._v("#")]),s._v(" Redis篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("基本操作，存储格式")]),s._v(" "),t("p",[s._v("略")])])]),s._v(" "),t("h4",{attrs:{id:"mysql篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mysql篇"}},[s._v("#")]),s._v(" Mysql篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("mysql集群的分布式事务")]),s._v(" "),t("p",[s._v("京东自主开发分布式MYSQL集群系统")])]),s._v(" "),t("li",[t("p",[s._v("mysql性能优化（数据方面）")]),s._v(" "),t("p",[s._v("数据的分表、分库、分区")])])]),s._v(" "),t("h4",{attrs:{id:"hadoop篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop篇"}},[s._v("#")]),s._v(" Hadoop篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("hadoop HA 两个namenode和zk之间的通信，zk的选举机制？")]),s._v(" "),t("p",[s._v("HA是通过先后获取zk的锁决定谁是主")]),s._v(" "),t("p",[s._v("Zk的选举机制，涉及到全新机群的选主和数据恢复的选主")])]),s._v(" "),t("li",[t("p",[s._v("mr运行机制")])])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1631015146340/image-20210907194545886.png",alt:"image-20210907194545886"}})]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[s._v("yarn流程")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1631015166515/image-20210907194606067.png",alt:"image-20210907194606067"}})]),s._v(" "),t("ol",[t("li",[t("p",[s._v("用户向 YARN 中提交应用程序， 其中包括 ApplicationMaster 程序、启动ApplicationMaster 的命 令、用户程序等。")])]),s._v(" "),t("li",[t("p",[s._v("ResourceManager 为该应用程序分配第一个 Container 并与对应的 NodeManager 通信，要求它在这个 Container 中启动应用程序的 ApplicationMaster")])]),s._v(" "),t("li",[t("p",[s._v("ApplicationMaster 首先向 ResourceManager 注册， 这样用户可以直接通过ResourceManage 查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤 4~7。")])]),s._v(" "),t("li",[t("p",[s._v("ApplicationMaster 采用轮询的方式通过 RPC 协议向 ResourceManager 申请和领取资源。")])]),s._v(" "),t("li",[t("p",[s._v("一旦 ApplicationMaster 申请到资源后，便与对应的 NodeManager 通信，要求它启动任务。")])]),s._v(" "),t("li",[t("p",[s._v("NodeManager 为任务设置好运行环境（包括环境变量、 JAR 包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。")])]),s._v(" "),t("li",[t("p",[s._v("各个任务通过某个 RPC 协议向 ApplicationMaster 汇报自己的状态和进度，以让ApplicationMaster 随时掌握各个任务的运行状 态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过 RPC 向 ApplicationMaster 查询应用程序的当前运行状态。")])]),s._v(" "),t("li",[t("p",[s._v("应用程序运行完成后， ApplicationMaster 向 ResourceManager 注销并关闭自己。")])])]),s._v(" "),t("h4",{attrs:{id:"hbase"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hbase"}},[s._v("#")]),s._v(" Hbase")]),s._v(" "),t("ol",[t("li",[s._v("涉及到概念，文档")])]),s._v(" "),t("h4",{attrs:{id:"spark篇"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark篇"}},[s._v("#")]),s._v(" Spark篇")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("spark原理")]),s._v(" "),t("p",[s._v("Spark应用转换流程")])])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1631015347974/image-20210907194907539.png",alt:"image-20210907194907539"}})]),s._v(" "),t("ol",[t("li",[s._v("spark应用提交后，经历了一系列的转换，最后成为task在每个节点上执行")]),s._v(" "),t("li",[s._v("RDD的Action算子触发Job的提交，生成RDD DAG")]),s._v(" "),t("li",[s._v("由DAGScheduler将RDD DAG转化为Stage DAG，每个Stage中产生相应的Task集合")]),s._v(" "),t("li",[s._v("TaskScheduler将任务分发到Executor执行")]),s._v(" "),t("li",[s._v("每个任务对应相应的一个数据块，只用用户定义的函数处理数据块")])]),s._v(" "),t("p",[t("strong",[s._v("Driver运行在 Worker上")])]),s._v(" "),t("p",[s._v("通过 org.apache.spark.deploy.Client类执行作业，作业运行命令如下：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1631015405898/image-20210907195005475.png",alt:"image-20210907195005475"}})]),s._v(" "),t("p",[s._v("作业执行流程描述：")]),s._v(" "),t("ol",[t("li",[s._v("客户端提交作业给 Master")]),s._v(" "),t("li",[s._v("Master让一个 Worker启动 Driver，即 SchedulerBackend。 Worker创建一个 DriverRunner线程， DriverRunner启动 SchedulerBackend进程。")]),s._v(" "),t("li",[s._v("另外 Master还会让其余 Worker启动 Exeuctor，即 ExecutorBackend。 Worker创建一个 ExecutorRunner线程， ExecutorRunner会启动 ExecutorBackend进程。")]),s._v(" "),t("li",[s._v("ExecutorBackend启动后会向 Driver的 SchedulerBackend注册。 SchedulerBackend进程中包含 DAGScheduler它会根据用户程序，生成执行计划，并调度执行。对于每个 stage的 task，都会被存放到 TaskScheduler中，ExecutorBackend向 SchedulerBackend汇报的时候把 TaskScheduler中的 task调度到 ExecutorBackend执 行。")]),s._v(" "),t("li",[s._v("所有 stage都完成后作业结束。")])]),s._v(" "),t("p",[t("strong",[s._v("Driver运行在客户端")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/vicxsl/img/raw/master/img/1631015463660/image-20210907195103244.png",alt:"image-20210907195103244"}})]),s._v(" "),t("p",[s._v("作业执行流程描述：")]),s._v(" "),t("ol",[t("li",[s._v("客户端启动后直接运行用户程序，启动 Driver相关的工作： DAGScheduler和 BlockManagerMaster等。")]),s._v(" "),t("li",[s._v("客户端的 Driver向 Master注册。")]),s._v(" "),t("li",[s._v("Master还会让 Worker启动 Exeuctor。 Worker创建一个 ExecutorRunner线程， ExecutorRunner会启动ExecutorBackend进程。")]),s._v(" "),t("li",[s._v("ExecutorBackend启动后会向 Driver的 SchedulerBackend注册。 Driver的 DAGScheduler解析作业并生成相应的 Stage，每个 Stage包含的 Task通过 TaskScheduler分配给 Executor执行。")]),s._v(" "),t("li",[s._v("所有 stage都完成后作业结束。")])])])}),[],!1,null,null,null);a.default=e.exports}}]);